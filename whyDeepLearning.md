#### Hardware

**NVIDIA** and **AMD** have invested billion of dollars in developing fast, 
massively parralel chips (Graphical Processing Unit).
This investment came to benefit the scientific community when,
in 2007, NVIDIA launched **CUDA**  [Gaming Interface](https://developer.nvidia.com/about-cuda), a programming interface for its line of GPUs.

Large companies train deep-learning models on clusters of hundreds of GPUs of a type developed specifically for the needs of deep learning, such as the
**NVIDIA Tesla K80**.

Google revealed its *tensor processing unit (TPU)* project: a new chip design developed from the ground up to run deep neural networks, which is
reportedly 10 times faster and far more energy efficient than top-of-the-line GPUs.

#### Deep Learning properies that justify it as the revolution of AI.

- *Simplicity*: Removes the need for feature engineering, replacing complex, brittle, engineering-heavy pipelines with simple, end-to-end trainable
models. (built using only five or six different tensor operations).
- *Scalability*: Deep-learning models are trained by iterating over small batches of data, allowing them to be trained on datasets of arbitrary size.
- *Versatility*: Deep-learning models can be trained on additional data without restarting from scratch - viable for continuous online learning— (large production models.)
- *Reusability*: It’s possible to take a deep-learning model trained for image classification and drop it into a video processing pipeline.

