{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Build a Text Classifier\n",
    "### (NVIDIA NeMo v1.0)\n",
    "\n",
    "<img style=\"float: right;\" src=\"images/nemo/nemo-app-stack.png\" width=400>\n",
    "\n",
    "In this notebook, you'll build an application to classify medical disease abstracts into one of three categories: cancer diseases, neurological diseases and disorders, and \"other\" for anything else.\n",
    "You'll use [NVIDIA NeMo](https://developer.nvidia.com/nvidia-nemo) (Neural Modules) to quickly set up the problem from the command line. \n",
    "\n",
    "**[2.1 NeMo Overview](#2.1-NeMo-Overview)**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.1.1 NeMo Models](#2.1.1-NeMo-Models)<br>\n",
    "**[2.2 Text Classification from the Command Line](#2.2-Text-Classification-from-the-Command-Line)**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.2.1 Prepare the Data](#2.2.1-Prepare-the-Data)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.2.2 Configuration File](#2.2.2-Configuration-File)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[2.2.2.1 OmegaConf Tool](#2.2.2.1-OmegaConf-Tool)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.2.3 Hydra-Enabled Python Script](#2.2.3-Hydra-Enabled-Python-Script)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.2.4 Exercise: Run an Experiment](#2.2.4-Exercise:-Run-an-Experiment)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.2.5 Visualize the Results with TensorBoard](#2.2.5-Visualize-the-Results-with-TensorBoard)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.2.6 Exercise: Change the Language Model (Optional!)](#2.2.6-Exercise:-Change-the-Language-Model-(Optional!))<br>\n",
    "**[2.3 PyTorch Lightning Model and Trainer Workflow](#2.3-PyTorch-Lightning-Model-and-Trainer-Workflow)**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.3.1 Script Key Features](#2.3.1-Script-Key-Features)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.3.2 Model Training from Scratch](#2.3.2-Model-Training-from-Scratch)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.3.3 Exercise: Query the Model](#2.3.3-Exercise:-Query-the-Model)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2.1 NeMo Overview\n",
    "NeMo is an open source toolkit for building conversational AI applications. NeMo is built around [Neural Modules](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/core/core.html#neural-modules), conceptual blocks of neural networks that take typed inputs and produce typed outputs. Such modules typically represent data layers, encoders, decoders, language models, loss functions, or methods of combining activations. NeMo makes it easy to combine and re-use these building blocks while providing a level of semantic correctness checking via its neural type system.\n",
    "\n",
    "The NeMo deep learning framework is based on [Pytorch Lightning](https://github.com/PyTorchLightning/pytorch-lightning), a PyTorch wrapper that organizes PyTorch code for neural network training.  PyTorch Lightning provides easy and high-performant multi-GPU/multi-node mixed precision training options. Creating a deep neural network project, or **experiment**, with PyTorch Lightning requires two main components:\n",
    "1. [LightningModule](https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html)\n",
    "2. [Trainer](https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html)\n",
    "\n",
    "The _LightningModule_ is used to organize PyTorch code into computation, optimizers, and loops for training, validation, and test.  This abstraction makes deep learning experiments easier to understand and reproduce. \n",
    "\n",
    "The _Trainer_ is then able to take the LightningModule and automate everything needed for deep learning training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.1 NeMo Models\n",
    "\n",
    "[NeMo models](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/core/core.html) are LightningModules that come equipped with all supporting infrastructure for training and reproducibility. This includes the deep learning model architecture, data preprocessing, optimizer, checkpoints, and experiment logging. NeMo models, like LightningModules, are also PyTorch modules and are fully compatible with the broader PyTorch ecosystem. Any NeMo model can be taken and plugged into any PyTorch workflow.  \n",
    "\n",
    "**Every NeMo model has an example configuration file and training script that can be found in the [NVIDIA NeMo GitHub Repo](https://github.com/NVIDIA/NeMo/tree/main/examples).**\n",
    "\n",
    "For this class, we'll use a local repo copy included in this environment, based on the downloadable [NGC NeMo container](https://ngc.nvidia.com/catalog/containers/nvidia:nemo), and focus on NLP models.  Execute the following cell to see a tree of NeMo models in the `examples/nlp` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mnemo/examples/nlp\u001b[00m\n",
      "├── \u001b[01;34mdialogue_state_tracking\u001b[00m\n",
      "│   ├── \u001b[01;34mconf\u001b[00m\n",
      "│   └── sgd_qa.py\n",
      "├── \u001b[01;34mentity_linking\u001b[00m\n",
      "│   ├── build_index.py\n",
      "│   ├── \u001b[01;34mconf\u001b[00m\n",
      "│   ├── \u001b[01;34mdata\u001b[00m\n",
      "│   ├── query_index.py\n",
      "│   └── self_alignment_pretraining.py\n",
      "├── \u001b[01;34mglue_benchmark\u001b[00m\n",
      "│   ├── glue_benchmark.py\n",
      "│   └── glue_benchmark_config.yaml\n",
      "├── \u001b[01;34minformation_retrieval\u001b[00m\n",
      "│   ├── bert_dpr.py\n",
      "│   ├── bert_joint_ir.py\n",
      "│   ├── \u001b[01;34mconf\u001b[00m\n",
      "│   ├── construct_random_negatives.py\n",
      "│   └── get_msmarco.sh\n",
      "├── \u001b[01;34mintent_slot_classification\u001b[00m\n",
      "│   ├── \u001b[01;34mconf\u001b[00m\n",
      "│   ├── \u001b[01;34mdata\u001b[00m\n",
      "│   └── intent_slot_classification.py\n",
      "├── \u001b[01;34mlanguage_modeling\u001b[00m\n",
      "│   ├── bert_pretraining.py\n",
      "│   ├── \u001b[01;34mconf\u001b[00m\n",
      "│   ├── convert_weights_to_nemo1.0.py\n",
      "│   ├── get_wkt2.sh\n",
      "│   └── transformer_lm.py\n",
      "├── \u001b[01;34mmachine_translation\u001b[00m\n",
      "│   ├── \u001b[01;34mconf\u001b[00m\n",
      "│   ├── create_tarred_monolingual_dataset.py\n",
      "│   ├── create_tarred_parallel_dataset.py\n",
      "│   ├── enc_dec_nmt.py\n",
      "│   ├── nmt_transformer_infer.py\n",
      "│   ├── \u001b[01;34mnmt_webapp\u001b[00m\n",
      "│   ├── preprocess_dataset.py\n",
      "│   └── translate_ddp.py\n",
      "├── \u001b[01;34mquestion_answering\u001b[00m\n",
      "│   ├── \u001b[01;34mconf\u001b[00m\n",
      "│   ├── \u001b[01;32mget_squad.py\u001b[00m\n",
      "│   └── question_answering_squad.py\n",
      "├── \u001b[01;34mtext2sparql\u001b[00m\n",
      "│   ├── \u001b[01;34mconf\u001b[00m\n",
      "│   ├── \u001b[01;34mdata\u001b[00m\n",
      "│   ├── evaluate_text2sparql.py\n",
      "│   └── text2sparql.py\n",
      "├── \u001b[01;34mtext_classification\u001b[00m\n",
      "│   ├── \u001b[01;34mconf\u001b[00m\n",
      "│   ├── \u001b[01;34mdata\u001b[00m\n",
      "│   ├── model_parallel_text_classification_evaluation.py\n",
      "│   └── text_classification_with_bert.py\n",
      "└── \u001b[01;34mtoken_classification\u001b[00m\n",
      "    ├── \u001b[01;34mconf\u001b[00m\n",
      "    ├── \u001b[01;34mdata\u001b[00m\n",
      "    ├── punctuation_capitalization_evaluate.py\n",
      "    ├── punctuation_capitalization_train.py\n",
      "    ├── token_classification_evaluate.py\n",
      "    └── token_classification_train.py\n",
      "\n",
      "27 directories, 31 files\n"
     ]
    }
   ],
   "source": [
    "!tree nemo/examples/nlp -L 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of models listed covering several classic NLP tasks.  We will focus on [text classification](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/nlp/text_classification.html) in this notebook and [token classification](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/nlp/token_classification.html) in the next notebook on named entity recognition (NER). \n",
    "\n",
    "Notice that each NeMo model type includes a `conf` folder for configuration files and at least one Python training script file.  \n",
    "\n",
    "Execute the following cell to see more detail for the text classification model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TC_DIR = \"/dli/task/nemo/examples/nlp/text_classification\"\n",
    "!tree $TC_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The config file, `text_classification_config.yaml`, specifies model, training, and experiment management details, such as file locations, pretrained models, and hyperparameters.\n",
    "\n",
    "The Python script, `text_classification_with_bert.py`, encapsulates everything you need to run a text classification experiment defined by the configuration file.  It employs Facebook's [Hydra](https://hydra.cc/) tool for configuration management, which allows you to run the entire experiment just with the script, using command line options to override the config values!\n",
    "\n",
    "The key to building an experiment quickly, is to  understand what the default config file includes, and what needs to be changed for your own project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2.2 Text Classification from the Command Line\n",
    "The question we want to answer is: \n",
    "\n",
    "**Given a medical disease abstract, is the abstract about cancer, a neurological disorder, or something else?**\n",
    "\n",
    "This is a 3-class text classification problem.  We'll use the NeMo [text classification model](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/nlp/text_classification.html) with three classes (labels): \"cancer\" (0), \"neurological disorders\" (1), and \"other\" (2).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.1 Prepare the Data\n",
    "You've already explored the [NCBI-disease corpus](https://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/) and the text classification dataset derived from it in the [Explore the Data](010_ExploreData.ipynb) notebook.  Recall that the text classification files consist of tab-delimited abstracts and labels, with a row of headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TC3_DATA_DIR = '/dli/task/data/NCBI_tc-3'\n",
    "!ls $TC3_DATA_DIR/*.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take a look at the tab separated data\n",
    "print(\"*****\\ntrain.tsv sample\\n*****\")\n",
    "!head -n 3 $TC3_DATA_DIR/train.tsv\n",
    "print(\"\\n\\n*****\\ndev.tsv sample\\n*****\")\n",
    "!head -n 3 $TC3_DATA_DIR/dev.tsv\n",
    "print(\"\\n\\n*****\\ntest.tsv sample\\n*****\")\n",
    "!head -n 3 $TC3_DATA_DIR/test.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Note a few features of the data:\n",
    "* The preprocessed data is already in the \n",
    "\n",
    "   ```\n",
    "   [WORD][SPACE][WORD][SPACE][WORD][TAB][LABEL]\n",
    "   ``` \n",
    "   format specified in the [documentation](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/nlp/text_classification.html).\n",
    "* There is a header row, \"sentence label\", that should be removed.\n",
    "* The text is quite long, so `max_seq_length` values will need to take this into account for training.\n",
    "\n",
    "Start by removing the header rows.  There are a number of ways to do this, but since it is a simple change we can use a bash stream editor (`sed`) command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed 1d $TC3_DATA_DIR/train.tsv > $TC3_DATA_DIR/train_nemo_format.tsv\n",
    "!sed 1d $TC3_DATA_DIR/dev.tsv > $TC3_DATA_DIR/dev_nemo_format.tsv\n",
    "!sed 1d $TC3_DATA_DIR/test.tsv > $TC3_DATA_DIR/test_nemo_format.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take a look at the tab separated data\n",
    "# \"1\" is \"positive\" and \"0\" is \"negative\"\n",
    "print(\"*****\\ntrain_nemo_format.tsv sample\\n*****\")\n",
    "!head -n 3 $TC3_DATA_DIR/train_nemo_format.tsv\n",
    "print(\"\\n\\n*****\\ndev_nemo_format.tsv sample\\n*****\")\n",
    "!head -n 3 $TC3_DATA_DIR/dev_nemo_format.tsv\n",
    "print(\"\\n\\n*****\\ntest_nemo_format.tsv sample\\n*****\")\n",
    "!head -n 3 $TC3_DATA_DIR/test_nemo_format.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TC3_DATA_DIR = '/dli/task/data/NCBI_tc-3'\n",
    "!ls $TC3_DATA_DIR/*.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2 Configuration File\n",
    "List the config file `text_classification_config.yaml` and take a look at the keys and default values.  Note the hierarchy of the keys and, especially, the three top-level keys: `trainer`, `model`, and `exp_manager`.\n",
    "\n",
    "```yaml\n",
    "trainer:\n",
    "  gpus:\n",
    "  num_nodes:\n",
    "  max_epochs:\n",
    "  ...\n",
    "  \n",
    "model:\n",
    "  nemo_path:\n",
    "  tokenizer:  \n",
    "  language_model:\n",
    "  classifier_head:\n",
    "  ...\n",
    "\n",
    "exp_manager:\n",
    "  ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "#     http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "\n",
      "# Config file for text classification with pre-trained BERT models\n",
      "\n",
      "trainer:\n",
      "  gpus: 1 # number of GPUs (0 for CPU), or list of the GPUs to use e.g. [0, 1]\n",
      "  num_nodes: 1\n",
      "  max_epochs: 100\n",
      "  max_steps: null # precedence over max_epochs\n",
      "  accumulate_grad_batches: 1 # accumulates grads every k batches\n",
      "  gradient_clip_val: 0.0\n",
      "  amp_level: O0 # O1/O2 for mixed precision\n",
      "  precision: 32 # Should be set to 16 for O1 and O2 to enable the AMP.\n",
      "  accelerator: ddp\n",
      "  log_every_n_steps: 1  # Interval of logging.\n",
      "  val_check_interval: 1.0  # Set to 0.25 to check 4 times per epoch, or an int for number of iterations\n",
      "  resume_from_checkpoint: null # The path to a checkpoint file to continue the training, restores the whole state including the epoch, step, LR schedulers, apex, etc.\n",
      "  num_sanity_val_steps: 0 # number of steps to perform validation steps for sanity check the validation process before starting the training, setting to 0 disables it\n",
      "\n",
      "  checkpoint_callback: False  # Provided by exp_manager\n",
      "  logger: False  # Provided by exp_manager\n",
      "\n",
      "model:\n",
      "  nemo_path: text_classification_model.nemo # filename to save the model and associated artifacts to .nemo file\n",
      "  tokenizer:\n",
      "      tokenizer_name: ${model.language_model.pretrained_model_name} # or sentencepiece\n",
      "      vocab_file: null # path to vocab file\n",
      "      tokenizer_model: null # only used if tokenizer is sentencepiece\n",
      "      special_tokens: null\n",
      "\n",
      "  language_model:\n",
      "    pretrained_model_name: bert-base-uncased\n",
      "    lm_checkpoint: null\n",
      "    config_file: null # json file, precedence over config\n",
      "    config: null\n",
      "\n",
      "  classifier_head:\n",
      "    num_output_layers: 2\n",
      "    fc_dropout: 0.1\n",
      "\n",
      "  class_labels:\n",
      "    class_labels_file : null # optional to specify a file containing the list of the labels\n",
      "\n",
      "  dataset:\n",
      "    num_classes: ??? # The number of classes. 0 < Label <num_classes.\n",
      "    do_lower_case: false # true for uncased models, false for cased models, will be set automatically if pre-trained tokenizer model is used\n",
      "    max_seq_length: 256 # the maximum length BERT supports is 512\n",
      "    class_balancing: null # null or 'weighted_loss'. 'weighted_loss' enables the weighted class balancing of the loss, may be used for handling unbalanced classes\n",
      "    use_cache: false # uses a cache to store the processed dataset, you may use it for large datasets for speed up\n",
      "\n",
      "  train_ds:\n",
      "    file_path: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    num_samples: -1 # number of samples to be considered, -1 means all the dataset\n",
      "    num_workers: 3\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "\n",
      "  validation_ds:\n",
      "    file_path: null\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    num_samples: -1 # number of samples to be considered, -1 means all the dataset\n",
      "    num_workers: 3\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "\n",
      "  test_ds:\n",
      "    file_path: null\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    num_samples: -1 # number of samples to be considered, -1 means all the dataset\n",
      "    num_workers: 3\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "\n",
      "  optim:\n",
      "    name: adam\n",
      "    lr: 2e-5\n",
      "    # optimizer arguments\n",
      "    betas: [0.9, 0.999]\n",
      "    weight_decay: 0.01\n",
      "\n",
      "    # scheduler setup\n",
      "    sched:\n",
      "      name: WarmupAnnealing\n",
      "      # Scheduler params\n",
      "      warmup_steps: null\n",
      "      warmup_ratio: 0.1\n",
      "      last_epoch: -1\n",
      "      # pytorch lightning args\n",
      "      monitor: val_loss\n",
      "      reduce_on_plateau: false\n",
      "\n",
      "  # List of some sample queries for inference after training is done\n",
      "  infer_samples: [\n",
      "    'by the end of no such thing the audience , like beatrice , has a watchful affection for the monster .',\n",
      "    'director rob marshall went out gunning to make a great one .',\n",
      "    'uneasy mishmash of styles and genres .',\n",
      "  ]\n",
      "\n",
      "exp_manager:\n",
      "  exp_dir: null  # exp_dir for your experiment, if None, defaults to \"./nemo_experiments\"\n",
      "  name: \"TextClassification\"  # The name of your model\n",
      "  create_tensorboard_logger: True  # Whether you want exp_manger to create a tb logger\n",
      "  create_checkpoint_callback: True  # Whether you want exp_manager to create a modelcheckpoint callback\n"
     ]
    }
   ],
   "source": [
    "CONFIG_DIR = \"/dli/task/nemo/examples/nlp/text_classification/conf\"\n",
    "CONFIG_FILE = \"text_classification_config.yaml\"\n",
    "!cat $CONFIG_DIR/$CONFIG_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2.1 OmegaConf Tool\n",
    "The YAML config file provides default values for most of the parameters, but there are a few items that must be specified for the text classification experiment in order to run it at all.  \n",
    "\n",
    "Each YAML section is a bit easier to view using the [omegaconf](https://omegaconf.readthedocs.io/en/2.1_branch/#) package, which allows you to access and manipulate the configuration keys using a \"dot\" protocol.  \n",
    "\n",
    "Start by instantiating an `OmegaConf` object from the config file. Keys in the object can be changed, added, viewed, saved, and so on.  \n",
    "\n",
    "For example, to look at just the `model` section, we can load the config file and specify just the `config.model` section to view through a print statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "config = OmegaConf.load(CONFIG_DIR + \"/\" + CONFIG_FILE)\n",
    "print(OmegaConf.to_yaml(config.model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details about the model arguments can be found in the [documentation](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/nlp/text_classification.html#model-arguments).  The `dataset.num_classes` value as well as locations of the data in `train_ds.file_path`, `val_ds.file_path`, and `test_ds.file_path` are required.\n",
    "\n",
    "To make sure we don't run out of memory, we can limit the `dataset.max_seq_length` to 128.  It also looks like the `infer_samples` are related to movie reviews, so we can change those to sentences that are meaningful in the disease domain.\n",
    "\n",
    "There are some other parameters we might want to change later, but for now, this is all we absolutely must provide.  \n",
    "\n",
    "Next take a look at the `trainer` subsection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OmegaConf.to_yaml(config.trainer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have one GPU right now, so that setting is fine, but we might want to limit the `max_epochs` to just a few to start with.  As with the `model` configs, there are some other parameters we might want to change, but we can go with the default for our first try.  \n",
    "\n",
    "Finally, what about the `exp_manager`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OmegaConf.to_yaml(config.exp_manager))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is fine as it is. When the `exp_dir` is `null`, it will default to placing the experiment results in a new directory named `nemo_experiments`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.3 Hydra-Enabled Python Script\n",
    "To recap, the parameters we need to change or override are:\n",
    "\n",
    "* `model.dataset.num_classes`: set to 3\n",
    "* `model.dataset.max_seq_length`: set to 128\n",
    "* `model.train_ds.file_path`: set to train_nemo_format.tsv\n",
    "* `model.val_ds.file_path`: set to dev_nemo_format.tsv\n",
    "* `model.test_ds.file_path`: set to test_nemo_format.tsv\n",
    "* `model.infer_samples` : set to relevent sentences\n",
    "* `trainer.max_epochs`: set to 3\n",
    "\n",
    "We can train, infer, and test it all **in one command** using the text classification training script!  \n",
    "\n",
    "The script uses Hydra to manage the config file, so that means we can just override the values we want to from the command line as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# The training takes about 2 minutes to run\n",
    "\n",
    "TC_DIR = \"/dli/task/nemo/examples/nlp/text_classification\"\n",
    "\n",
    "# set the values we want to override\n",
    "NUM_CLASSES = 3\n",
    "MAX_SEQ_LENGTH = 128\n",
    "PATH_TO_TRAIN_FILE = \"/dli/task/data/NCBI_tc-3/train_nemo_format.tsv\"\n",
    "PATH_TO_VAL_FILE = \"/dli/task/data/NCBI_tc-3/dev_nemo_format.tsv\"\n",
    "PATH_TO_TEST_FILE = \"/dli/task/data/NCBI_tc-3/test_nemo_format.tsv\"\n",
    "# disease domain inference sample answers should be 0, 1, 2 \n",
    "INFER_SAMPLES_0 = \"In contrast no mutations were detected in the p53 gene suggesting that this tumour suppressor is not frequently altered in this leukaemia \"\n",
    "INFER_SAMPLES_1 = \"The first predictive testing for Huntington disease  was based on analysis of linked polymorphic DNA markers to estimate the likelihood of inheriting the mutation for HD\"\n",
    "INFER_SAMPLES_2 = \"Further studies suggested that low dilutions of C5D serum contain a factor or factors interfering at some step in the hemolytic assay of C5 rather than a true C5 inhibitor or inactivator\"\n",
    "MAX_EPOCHS = 3\n",
    "\n",
    "# Run the training script, overriding the config values in the command line\n",
    "!python $TC_DIR/text_classification_with_bert.py \\\n",
    "        model.dataset.num_classes=$NUM_CLASSES \\\n",
    "        model.dataset.max_seq_length=$MAX_SEQ_LENGTH \\\n",
    "        model.train_ds.file_path=$PATH_TO_TRAIN_FILE \\\n",
    "        model.validation_ds.file_path=$PATH_TO_VAL_FILE \\\n",
    "        model.test_ds.file_path=$PATH_TO_TEST_FILE \\\n",
    "        model.infer_samples=[\"$INFER_SAMPLES_0\",\"$INFER_SAMPLES_1\",\"$INFER_SAMPLES_2\"] \\\n",
    "        trainer.max_epochs=$MAX_EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the start of each training experiment, there is a printed log of the experiment specification including any parameters added or overridden via the command-line. It also shows additional information, such as which GPUs are available, where logs are saved, and some samples from the datasets with their corresponding inputs to the model. The log also provides some stats on the lengths of sequences in the dataset.\n",
    "\n",
    "After each epoch, there is a summary table of metrics on the validation set which includes precision, recall, and f1 score. The f1 score takes both false positives and false negatives into account and is considered more useful than simple accuracy. \n",
    "\n",
    "At the end of training, NeMo saves the last checkpoint at the path specified by `model.nemo_file_path`.  Since we left this value at the default, it should have been written to our workspace in `.nemo` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls *.nemo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results you achieved in the experiment may not have been very good.  However, it is pretty easy to try another experiment with just a few changes.  Longer training, adjusted learning rate, and changing the batch size for the training and validation datasets can improve results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.4 Exercise: Run an Experiment\n",
    "Try running another similar experiment using the same text classification problem, this time with some suggested improvements:\n",
    "  \n",
    "* Set the mixed-precision `amp_level` to \"O1\" with a `precision` of 16 to make the model run faster with little or no reduction in accuracy.\n",
    "* Adjust the number of epochs upward a bit to improve results (larger `max_epochs`)\n",
    "* Increase the learning rate a little to allow more rapid response to the estimated error each time the model weights are updated\n",
    "\n",
    "The new values have been provided for you in the cell below.  Add the command with appropriate overrides and run the cell.  If you get stuck, refer to the [solution](solutions/ex2.2.4.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# The training takes about 2 minutes to run\n",
    "\n",
    "TC_DIR = \"/dli/task/nemo/examples/nlp/text_classification\"\n",
    "\n",
    "# set the values we want to override\n",
    "NUM_CLASSES = 3\n",
    "MAX_SEQ_LENGTH = 128\n",
    "PATH_TO_TRAIN_FILE = \"/dli/task/data/NCBI_tc-3/train_nemo_format.tsv\"\n",
    "PATH_TO_VAL_FILE = \"/dli/task/data/NCBI_tc-3/dev_nemo_format.tsv\"\n",
    "PATH_TO_TEST_FILE = \"/dli/task/data/NCBI_tc-3/test_nemo_format.tsv\"\n",
    "# disease domain inference sample answers should be 0, 1, 2 \n",
    "INFER_SAMPLES_0 = \"In contrast no mutations were detected in the p53 gene suggesting that this tumour suppressor is not frequently altered in this leukaemia \"\n",
    "INFER_SAMPLES_1 = \"The first predictive testing for Huntington disease  was based on analysis of linked polymorphic DNA markers to estimate the likelihood of inheriting the mutation for HD\"\n",
    "INFER_SAMPLES_2 = \"Further studies suggested that low dilutions of C5D serum contain a factor or factors interfering at some step in the hemolytic assay of C5 rather than a true C5 inhibitor or inactivator\"\n",
    "MAX_EPOCHS = 5\n",
    "AMP_LEVEL = 'O1'\n",
    "PRECISION = 16\n",
    "LR = 5.0e-05\n",
    "BATCH_SIZE = 32\n",
    "# Override the config values in the command line\n",
    "!python $TC_DIR/text_classification_with_bert.py \\\n",
    "        model.dataset.num_classes=$NUM_CLASSES \\\n",
    "        model.dataset.max_seq_length=$MAX_SEQ_LENGTH \\\n",
    "        model.train_ds.file_path=$PATH_TO_TRAIN_FILE \\\n",
    "        model.validation_ds.file_path=$PATH_TO_VAL_FILE \\\n",
    "        model.test_ds.file_path=$PATH_TO_TEST_FILE \\\n",
    "        model.infer_samples=[\"$INFER_SAMPLES_0\",\"$INFER_SAMPLES_1\",\"$INFER_SAMPLES_2\"] \\\n",
    "        trainer.max_epochs=$MAX_EPOCHS \\\n",
    "        trainer.amp_level=$AMP_LEVEL \\\n",
    "        trainer.precision=$PRECISION \\\n",
    "        model.train_ds.batch_size =$BATCH_SIZE \\\n",
    "        model.optim.lr=$LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did the result from this experiment compare to the previous one?  Check the F1 scores and inference results in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.5 Visualize the Results with TensorBoard\n",
    "The [experiment manager](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/core/core.html?highlight=tensorboard#experiment-manager) saves results for viewing with TensorBoard. Execute the following cell to create a link to TensorBoard for your instance, then click on the link to open Tensorboard in a tab on your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%js\n",
    "const href = window.location.hostname +'/tensorboard/';\n",
    "let a = document.createElement('a');\n",
    "let link = document.createTextNode('Open Tensorboard!');\n",
    "a.appendChild(link);\n",
    "a.href = \"http://\" + href;\n",
    "a.style.color = \"navy\"\n",
    "a.target = \"_blank\"\n",
    "element.append(a);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "To compare the performance of the models you've run, select the \"train loss\" scaler.  You can see all the models you've run compared together or select individual models for comparison.  The example below shows the first experiment in orange and the exercise experiment in blue.  You can see that the loss was smaller in the second experiment.\n",
    "\n",
    "<img src=\"images/tensorboard_01.png\" width=1000px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.6 Exercise: Change the Language Model\n",
    "So far, you've used the basic `bert-base-uncased` language model, but that is just one of many you could try.  Run the following cell to see what language models are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['megatron-bert-345m-uncased',\n",
       " 'megatron-bert-345m-cased',\n",
       " 'megatron-bert-uncased',\n",
       " 'megatron-bert-cased',\n",
       " 'biomegatron-bert-345m-uncased',\n",
       " 'biomegatron-bert-345m-cased',\n",
       " 'bert-base-uncased',\n",
       " 'bert-large-uncased',\n",
       " 'bert-base-cased',\n",
       " 'bert-large-cased',\n",
       " 'bert-base-multilingual-uncased',\n",
       " 'bert-base-multilingual-cased',\n",
       " 'bert-base-chinese',\n",
       " 'bert-base-german-cased',\n",
       " 'bert-large-uncased-whole-word-masking',\n",
       " 'bert-large-cased-whole-word-masking',\n",
       " 'bert-large-uncased-whole-word-masking-finetuned-squad',\n",
       " 'bert-large-cased-whole-word-masking-finetuned-squad',\n",
       " 'bert-base-cased-finetuned-mrpc',\n",
       " 'bert-base-german-dbmdz-cased',\n",
       " 'bert-base-german-dbmdz-uncased',\n",
       " 'cl-tohoku/bert-base-japanese',\n",
       " 'cl-tohoku/bert-base-japanese-whole-word-masking',\n",
       " 'cl-tohoku/bert-base-japanese-char',\n",
       " 'cl-tohoku/bert-base-japanese-char-whole-word-masking',\n",
       " 'TurkuNLP/bert-base-finnish-cased-v1',\n",
       " 'TurkuNLP/bert-base-finnish-uncased-v1',\n",
       " 'wietsedv/bert-base-dutch-cased',\n",
       " 'distilbert-base-uncased',\n",
       " 'distilbert-base-uncased-distilled-squad',\n",
       " 'distilbert-base-cased',\n",
       " 'distilbert-base-cased-distilled-squad',\n",
       " 'distilbert-base-german-cased',\n",
       " 'distilbert-base-multilingual-cased',\n",
       " 'distilbert-base-uncased-finetuned-sst-2-english',\n",
       " 'roberta-base',\n",
       " 'roberta-large',\n",
       " 'roberta-large-mnli',\n",
       " 'distilroberta-base',\n",
       " 'roberta-base-openai-detector',\n",
       " 'roberta-large-openai-detector',\n",
       " 'albert-base-v1',\n",
       " 'albert-large-v1',\n",
       " 'albert-xlarge-v1',\n",
       " 'albert-xxlarge-v1',\n",
       " 'albert-base-v2',\n",
       " 'albert-large-v2',\n",
       " 'albert-xlarge-v2',\n",
       " 'albert-xxlarge-v2']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# complete list of supported BERT-like models\n",
    "from nemo.collections import nlp as nemo_nlp\n",
    "nemo_nlp.modules.get_pretrained_lm_models_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, choose a new language model, such as `megatron-bert-345m-cased`.  \n",
    "\n",
    "You may need to restart the notebook kernal to clear memory.  If you use a large model, other ways to save GPU memory space are to reduce the `batch_size` to 32, 16, or even 8 and reduce the `max_seq_length` to 64. There is no right answer to this exercise.  Rather, this is an opportunity for you to experiment.  Some of the models can take several minutes to run, so feel free to move on to the next notebook and return here when you have time later. If you get stuck, take a look at an example [solution](solutions/ex2.2.6.ipynb).  Be sure to take note of the loss and f1 results with this model, or check TensorBoard for a visualization of the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restart the kernel\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2021-10-05 12:37:31 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/omegaconf/basecontainer.py:225: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.\n",
      "    Use OmegaConf.to_yaml(cfg)\n",
      "    \n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo I 2021-10-05 12:37:31 text_classification_with_bert:110] \n",
      "    Config Params:\n",
      "    trainer:\n",
      "      gpus: 1\n",
      "      num_nodes: 1\n",
      "      max_epochs: 5\n",
      "      max_steps: null\n",
      "      accumulate_grad_batches: 1\n",
      "      gradient_clip_val: 0.0\n",
      "      amp_level: O1\n",
      "      precision: 16\n",
      "      accelerator: ddp\n",
      "      log_every_n_steps: 1\n",
      "      val_check_interval: 1.0\n",
      "      resume_from_checkpoint: null\n",
      "      num_sanity_val_steps: 0\n",
      "      checkpoint_callback: false\n",
      "      logger: false\n",
      "    model:\n",
      "      nemo_path: text_classification_model.nemo\n",
      "      tokenizer:\n",
      "        tokenizer_name: ${model.language_model.pretrained_model_name}\n",
      "        vocab_file: null\n",
      "        tokenizer_model: null\n",
      "        special_tokens: null\n",
      "      language_model:\n",
      "        pretrained_model_name: megatron-bert-345m-cased\n",
      "        lm_checkpoint: null\n",
      "        config_file: null\n",
      "        config: null\n",
      "      classifier_head:\n",
      "        num_output_layers: 2\n",
      "        fc_dropout: 0.1\n",
      "      class_labels:\n",
      "        class_labels_file: null\n",
      "      dataset:\n",
      "        num_classes: 3\n",
      "        do_lower_case: false\n",
      "        max_seq_length: 64\n",
      "        class_balancing: null\n",
      "        use_cache: false\n",
      "      train_ds:\n",
      "        file_path: /dli/task/data/NCBI_tc-3/train_nemo_format.tsv\n",
      "        batch_size: 32\n",
      "        shuffle: true\n",
      "        num_samples: -1\n",
      "        num_workers: 3\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "      validation_ds:\n",
      "        file_path: /dli/task/data/NCBI_tc-3/dev_nemo_format.tsv\n",
      "        batch_size: 32\n",
      "        shuffle: false\n",
      "        num_samples: -1\n",
      "        num_workers: 3\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "      test_ds:\n",
      "        file_path: /dli/task/data/NCBI_tc-3/test_nemo_format.tsv\n",
      "        batch_size: 32\n",
      "        shuffle: false\n",
      "        num_samples: -1\n",
      "        num_workers: 3\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "      optim:\n",
      "        name: adam\n",
      "        lr: 5.0e-05\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        weight_decay: 0.01\n",
      "        sched:\n",
      "          name: WarmupAnnealing\n",
      "          warmup_steps: null\n",
      "          warmup_ratio: 0.1\n",
      "          last_epoch: -1\n",
      "          monitor: val_loss\n",
      "          reduce_on_plateau: false\n",
      "      infer_samples:\n",
      "      - In contrast no mutations were detected in the p53 gene suggesting that this tumour\n",
      "        suppressor is not frequently altered in this leukaemia\n",
      "      - The first predictive testing for Huntington disease  was based on analysis of\n",
      "        linked polymorphic DNA markers to estimate the likelihood of inheriting the mutation\n",
      "        for HD\n",
      "      - Further studies suggested that low dilutions of C5D serum contain a factor or\n",
      "        factors interfering at some step in the hemolytic assay of C5 rather than a true\n",
      "        C5 inhibitor or inactivator\n",
      "    exp_manager:\n",
      "      exp_dir: null\n",
      "      name: TextClassification\n",
      "      create_tensorboard_logger: true\n",
      "      create_checkpoint_callback: true\n",
      "    \n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Using native 16bit precision.\n",
      "[NeMo I 2021-10-05 12:37:31 exp_manager:216] Experiments will be logged at /dli/task/nemo_experiments/TextClassification/2021-10-05_12-37-31\n",
      "[NeMo I 2021-10-05 12:37:31 exp_manager:563] TensorboardLogger has been set up\n",
      "[NeMo I 2021-10-05 12:37:31 megatron_utils:274] Downloading from https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-vocab.txt\n",
      "100% [........................................................] 213450 / 213450Lock 140705668376320 acquired on /root/.cache/huggingface/transformers/11ad22b0deaa199d15b331609ca5f60872a1a91473e9b40c115192dadb6d9a30.bdf0177a774dcff07681b2527b926c099e6563687c75a79f7469c7a7da7898c7.lock\n",
      "Downloading: 100%|██████████████████████████████| 762/762 [00:00<00:00, 685kB/s]\n",
      "Lock 140705668376320 released on /root/.cache/huggingface/transformers/11ad22b0deaa199d15b331609ca5f60872a1a91473e9b40c115192dadb6d9a30.bdf0177a774dcff07681b2527b926c099e6563687c75a79f7469c7a7da7898c7.lock\n",
      "Lock 140705668375648 acquired on /root/.cache/huggingface/transformers/c9961ea5b7e8ad58701728c45f4d225f70b19aa59745121e5a96c8a44efca4c8.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791.lock\n",
      "Downloading: 100%|███████████████████████████| 213k/213k [00:00<00:00, 47.0MB/s]\n",
      "Lock 140705668375648 released on /root/.cache/huggingface/transformers/c9961ea5b7e8ad58701728c45f4d225f70b19aa59745121e5a96c8a44efca4c8.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791.lock\n",
      "Lock 140705668601360 acquired on /root/.cache/huggingface/transformers/45d2aa048795efc7b12791662c188d5e3aa2f9ac54b2cf3f6e4d7bc6544e3d13.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f.lock\n",
      "Downloading: 100%|███████████████████████████| 29.0/29.0 [00:00<00:00, 35.0kB/s]\n",
      "Lock 140705668601360 released on /root/.cache/huggingface/transformers/45d2aa048795efc7b12791662c188d5e3aa2f9ac54b2cf3f6e4d7bc6544e3d13.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f.lock\n",
      "Lock 140705670050720 acquired on /root/.cache/huggingface/transformers/75be22d7750034989358861e325977feda47740e1c3f8a4dc1cb73570aad843e.2b9a196704f2f183fe3f4b48d6e662dba8203fdcb3346bfa896831378edf6f97.lock\n",
      "Downloading: 100%|███████████████████████████| 436k/436k [00:00<00:00, 49.1MB/s]\n",
      "Lock 140705670050720 released on /root/.cache/huggingface/transformers/75be22d7750034989358861e325977feda47740e1c3f8a4dc1cb73570aad843e.2b9a196704f2f183fe3f4b48d6e662dba8203fdcb3346bfa896831378edf6f97.lock\n",
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "[NeMo I 2021-10-05 12:37:31 text_classification_dataset:120] Read 683 examples from /dli/task/data/NCBI_tc-3/train_nemo_format.tsv.\n",
      "[NeMo I 2021-10-05 12:37:31 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2021-10-05 12:37:31 text_classification_dataset:239] example 0: ['Novel', 'mutations', 'in', 'the', 'Wiskott-Aldrich', 'syndrome', 'protein', 'gene', 'and', 'their', 'effects', 'on', 'transcriptional,', 'translational,', 'and', 'clinical', 'phenotypes.', 'Wiskott-Aldrich', 'syndrome', '(', 'WAS', ')', 'is', 'an', 'X-linked', 'recessive', 'immunodeficiency', 'characterized', 'by', 'thrombocytopenia', ',', 'eczema', ',', 'and', 'recurrent', 'infections', ',', 'and', 'caused', 'by', 'mutations', 'in', 'the', 'WAS', 'protein', '(', 'WASP', ')', 'gene', '.', 'WASP', 'contains', 'several', 'functional', 'domains', 'through', 'which', 'it', 'interacts', 'with', 'proteins', 'involved', 'in', 'intracellular', 'signaling', 'and', 'regulation', 'of', 'the', 'actin', 'cytoskeleton', '.', 'In', 'this', 'report', ',', '17', 'WASP', 'gene', 'mutations', 'were', 'identified', ',', '12', 'of', 'which', 'are', 'novel', '.', 'DNA', 'of', 'affected', 'males', 'and', 'obligate', 'carriers', 'was', 'PCR', 'amplified', 'and', 'analyzed', 'by', 'SSCA', ',', 'heteroduplex', 'analysis', ',', 'and', 'direct', 'sequencing', '.', 'The', 'effects', 'of', 'the', 'mutations', 'at', 'the', 'mRNA', 'and', 'protein', 'level', 'were', 'ascertained', 'by', 'RT-PCR', 'and', 'Western', 'blot', 'analyses', '.', 'All', 'missense', 'mutations', 'were', 'located', 'in', 'exons', '1-4', '.', 'Most', 'of', 'the', 'nonsense', ',', 'frameshift', 'and', 'splice', 'site', 'mutations', 'were', 'found', 'in', 'exons', '6-11', '.', 'Mutations', 'that', 'alter', 'splice', 'sites', 'led', 'to', 'the', 'synthesis', 'of', 'several', 'types', 'of', 'mRNAs', ',', 'a', 'fraction', 'of', 'which', 'represented', 'the', 'normally', 'spliced', 'product', '.', 'The', 'presence', 'of', 'normally', 'spliced', 'transcripts', 'was', 'correlated', 'with', 'a', 'milder', 'phenotype', '.', 'When', 'one', 'such', 'case', 'was', 'studied', 'by', 'Western', 'blotting', ',', 'reduced', 'amounts', 'of', 'normal-size', 'WASP', 'were', 'present', '.', 'In', 'other', 'cases', 'as', 'well', ',', 'a', 'correlation', 'was', 'found', 'between', 'the', 'amount', 'of', 'normal', 'or', 'mutant', 'WASP', 'present', 'and', 'the', 'phenotypes', 'of', 'the', 'affected', 'individuals', '.', 'No', 'protein', 'was', 'detected', 'in', 'two', 'individuals', 'with', 'severe', 'WAS', '.', 'Reduced', 'levels', 'of', 'a', 'normal-size', 'WASP', 'with', 'a', 'missense', 'mutation', 'were', 'seen', 'in', 'two', 'individuals', 'with', 'XLT', '.', 'It', 'is', 'concluded', 'that', 'mutation', 'analysis', 'at', 'the', 'DNA', 'level', 'is', 'not', 'sufficient', 'for', 'predicting', 'clinical', 'course', '.', 'Studies', 'at', 'the', 'transcript', 'and', 'protein', 'level', 'are', 'needed', 'for', 'a', 'better', 'assessment', '.', '.']\n",
      "[NeMo I 2021-10-05 12:37:31 text_classification_dataset:240] subtokens: [CLS] Novel mutations in the W ##isk ##ott - Al ##dric ##h syndrome protein gene and their effects on transcription ##al , translation ##al , and clinical p ##hen ##otype ##s . W ##isk ##ott - Al ##dric ##h syndrome ( WA ##S ) is an X - linked re ##cess ##ive im ##mu ##no ##de ##ficiency characterized by th ##rom ##bo ##cy ##top [SEP]\n",
      "[NeMo I 2021-10-05 12:37:31 text_classification_dataset:241] input_ids: 101 16912 17157 1107 1103 160 13189 15719 118 2586 27168 1324 9318 4592 5565 1105 1147 3154 1113 15416 1348 117 5179 1348 117 1105 7300 185 10436 27172 1116 119 160 13189 15719 118 2586 27168 1324 9318 113 22751 1708 114 1110 1126 161 118 5128 1231 22371 2109 13280 13601 2728 2007 23622 6858 1118 24438 16071 4043 3457 9870 102\n",
      "[NeMo I 2021-10-05 12:37:31 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2021-10-05 12:37:31 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2021-10-05 12:37:31 text_classification_dataset:244] label: 2\n",
      "[NeMo I 2021-10-05 12:37:31 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2021-10-05 12:37:31 text_classification_dataset:239] example 1: ['Mutation', 'spectrum', 'and', 'genotype-phenotype', 'analyses', 'in', 'Cowden', 'disease', 'and', 'Bannayan-Zonana', 'syndrome,', 'two', 'hamartoma', 'syndromes', 'with', 'germline', 'PTEN', 'mutation.', 'The', 'tumour', 'suppressor', 'gene', 'PTEN', ',', 'which', 'maps', 'to', '10q23', '.', '3', 'and', 'encodes', 'a', '403', 'amino', 'acid', 'dual', 'specificity', 'phosphatase', '(', 'protein', 'tyrosine', 'phosphatase', ';', 'PTPase', ')', ',', 'was', 'shown', 'recently', 'to', 'play', 'a', 'broad', 'role', 'in', 'human', 'malignancy', '.', 'Somatic', 'PTEN', 'deletions', 'and', 'mutations', 'were', 'observed', 'in', 'sporadic', 'breast', ',', 'brain', ',', 'prostate', 'and', 'kidney', 'cancer', 'cell', 'lines', 'and', 'in', 'several', 'primary', 'tumours', 'such', 'as', 'endometrial', 'carcinomas', ',', 'malignant', 'melanoma', 'and', 'thyroid', 'tumours', '.', 'In', 'addition', ',', 'PTEN', 'was', 'identified', 'as', 'the', 'susceptibility', 'gene', 'for', 'two', 'hamartoma', 'syndromes', 'Cowden', 'disease', '(', 'CD', ';', 'MIM', '158350', ')', 'and', 'Bannayan-Zonana', '(', 'BZS', ')', 'or', 'Ruvalcaba-Riley-Smith', 'syndrome', '(', 'MIM', '153480', ')', '.', 'Constitutive', 'DNA', 'from', '37', 'CD', 'families', 'and', 'seven', 'BZS', 'families', 'was', 'screened', 'for', 'germline', 'PTEN', 'mutations', '.', 'PTEN', 'mutations', 'were', 'identified', 'in', '30', 'of', '37', '(', '81', '%', ')', 'CD', 'families', ',', 'including', 'missense', 'and', 'nonsense', 'point', 'mutations', ',', 'deletions', ',', 'insertions', ',', 'a', 'deletion', '/', 'insertion', 'and', 'splice', 'site', 'mutations', '.', 'These', 'mutations', 'were', 'scattered', 'over', 'the', 'entire', 'length', 'of', 'PTEN', ',', 'with', 'the', 'exception', 'of', 'the', 'first', ',', 'fourth', 'and', 'last', 'exons', '.', 'A', 'hot', 'spot', 'for', 'PTEN', 'mutation', 'in', 'CD', 'was', 'identified', 'in', 'exon', '5', 'that', 'contains', 'the', 'PTPase', 'core', 'motif', ',', 'with', '13', 'of', '30', '(', '43', '%', ')', 'CD', 'mutations', 'identified', 'in', 'this', 'exon', '.', 'Seven', 'of', '30', '(', '23', '%', ')', 'were', 'within', 'the', 'core', 'motif', ',', 'the', 'majority', '(', 'five', 'of', 'seven', ')', 'of', 'which', 'were', 'missense', 'mutations', ',', 'possibly', 'pointing', 'to', 'the', 'functional', 'significance', 'of', 'this', 'region', '.', 'Germline', 'PTEN', 'mutations', 'were', 'identified', 'in', 'four', 'of', 'seven', '(', '57', '%', ')', 'BZS', 'families', 'studied', '.', 'Interestingly', ',', 'none', 'of', 'these', 'mutations', 'was', 'observed', 'in', 'the', 'PTPase', 'core', 'motif', '.', 'It', 'is', 'also', 'worthy', 'of', 'note', 'that', 'a', 'single', 'nonsense', 'point', 'mutation', ',', 'R233X', ',', 'was', 'observed', 'in', 'the', 'germline', 'DNA', 'from', 'two', 'unrelated', 'CD', 'families', 'and', 'one', 'BZS', 'family', '.', 'Genotype-phenotype', 'studies', 'were', 'not', 'performed', 'on', 'this', 'small', 'group', 'of', 'BZS', 'families', '.', 'However', ',', 'genotype-phenotype', 'analysis', 'inthe', 'group', 'of', 'CD', 'families', 'revealed', 'two', 'possible', 'associations', 'worthy', 'of', 'follow-up', 'in', 'independent', 'analyses', '.', 'The', 'first', 'was', 'an', 'association', 'noted', 'in', 'the', 'group', 'of', 'CD', 'families', 'with', 'breast', 'disease', '.', 'A', 'correlation', 'was', 'observed', 'between', 'the', 'presence', '/', 'absence', 'of', 'a', 'PTEN', 'mutation', 'and', 'the', 'type', 'of', 'breast', 'involvement', '(', 'unaffected', 'versus', 'benign', 'versus', 'malignant', ')', '.', 'Specifically', 'and', 'more', 'directly', ',', 'an', 'association', 'was', 'also', 'observed', 'between', 'the', 'presence', 'of', 'a', 'PTEN', 'mutation', 'and', 'malignant', 'breast', 'disease', '.', 'Secondly', ',', 'there', 'appeared', 'to', 'be', 'an', 'interdependent', 'association', 'between', 'mutations', 'upstream', 'and', 'within', 'the', 'PTPase', 'core', 'motif', ',', 'the', 'core', 'motif', 'containing', 'the', 'majority', 'of', 'missense', 'mutations', ',', 'and', 'the', 'involvement', 'of', 'all', 'major', 'organ', 'systems', '(', 'central', 'nervous', 'system', ',', 'thyroid', ',', 'breast', ',', 'skin', 'and', 'gastrointestinal', 'tract', ')', '.', 'However', ',', 'these', 'observations', 'would', 'need', 'to', 'be', 'confirmed', 'by', 'studying', 'a', 'larger', 'number', 'of', 'CD', 'families', '.']\n",
      "[NeMo I 2021-10-05 12:37:31 text_classification_dataset:240] subtokens: [CLS] Mu ##tation spectrum and g ##eno ##type - p ##hen ##otype analyses in Co ##w ##den disease and Ban ##nay ##an - Z ##ona ##na syndrome , two ha ##mart ##oma syndrome ##s with g ##er ##m ##line PT ##EN mutation . The t ##umour suppress ##or gene PT ##EN , which maps to 10 ##q ##23 . 3 and en ##codes a [SEP]\n",
      "[NeMo I 2021-10-05 12:37:31 text_classification_dataset:241] input_ids: 101 19569 7984 10122 1105 176 26601 15177 118 185 10436 27172 18460 1107 3291 2246 2883 3653 1105 18393 16691 1389 118 163 7637 1605 9318 117 1160 5871 22736 7903 9318 1116 1114 176 1200 1306 2568 22216 11680 17895 119 1109 189 27226 17203 1766 5565 22216 11680 117 1134 7415 1106 1275 4426 22737 119 124 1105 4035 25634 170 102\n",
      "[NeMo I 2021-10-05 12:37:31 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2021-10-05 12:37:31 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2021-10-05 12:37:31 text_classification_dataset:244] label: 0\n",
      "[NeMo W 2021-10-05 12:37:39 text_classification_dataset:250] Found 683 out of 683 sentences with more than 64 subtokens. Truncated long sentences from the end.\n",
      "[NeMo I 2021-10-05 12:37:39 data_preprocessing:299] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2021-10-05 12:37:39 data_preprocessing:301] Min: 65 |                  Max: 65 |                  Mean: 65.0 |                  Median: 65.0\n",
      "[NeMo I 2021-10-05 12:37:39 data_preprocessing:307] 75 percentile: 65.00\n",
      "[NeMo I 2021-10-05 12:37:39 data_preprocessing:308] 99 percentile: 65.00\n",
      "[NeMo I 2021-10-05 12:37:39 text_classification_dataset:120] Read 100 examples from /dli/task/data/NCBI_tc-3/dev_nemo_format.tsv.\n",
      "[NeMo I 2021-10-05 12:37:39 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2021-10-05 12:37:39 text_classification_dataset:239] example 0: ['BRCA1', 'is', 'secreted', 'and', 'exhibits', 'properties', 'of', 'a', 'granin.', 'Germline', 'mutations', 'in', 'BRCA1', 'are', 'responsible', 'for', 'most', 'cases', 'of', 'inherited', 'breast', 'and', 'ovarian', 'cancer', '.', 'However', ',', 'the', 'function', 'of', 'the', 'BRCA1', 'protein', 'has', 'remained', 'elusive', '.', 'We', 'now', 'show', 'that', 'BRCA1', 'encodes', 'a', '190-kD', 'protein', 'with', 'sequence', 'homology', 'and', 'biochemical', 'analogy', 'to', 'the', 'granin', 'protein', 'family', '.', 'Interestingly', ',', 'BRCA2', 'also', 'includes', 'a', 'motif', 'similar', 'to', 'the', 'granin', 'consensus', 'at', 'the', 'C', 'terminus', 'of', 'the', 'protein', '.', 'Both', 'BRCA1', 'and', 'the', 'granins', 'localize', 'to', 'secretory', 'vesicles', ',', 'are', 'secreted', 'by', 'a', 'regulated', 'pathway', ',', 'are', 'post-translationally', 'glycosylated', 'and', 'are', 'responsive', 'to', 'hormones', '.', 'As', 'a', 'regulated', 'secretory', 'protein', ',', 'BRCA1', 'appears', 'to', 'function', 'by', 'a', 'mechanism', 'not', 'previously', 'described', 'for', 'tumour', 'suppressor', 'gene', 'products', '.', '.']\n",
      "[NeMo I 2021-10-05 12:37:39 text_classification_dataset:240] subtokens: [CLS] BR ##CA ##1 is secret ##ed and exhibits properties of a g ##rani ##n . G ##er ##m ##line mutations in BR ##CA ##1 are responsible for most cases of inherited breast and o ##var ##ian cancer . However , the function of the BR ##CA ##1 protein has remained el ##usive . We now show that BR ##CA ##1 en ##codes a [SEP]\n",
      "[NeMo I 2021-10-05 12:37:39 text_classification_dataset:241] input_ids: 101 26660 11356 1475 1110 3318 1174 1105 10877 4625 1104 170 176 23851 1179 119 144 1200 1306 2568 17157 1107 26660 11356 1475 1132 2784 1111 1211 2740 1104 7459 7209 1105 184 8997 1811 4182 119 1438 117 1103 3053 1104 1103 26660 11356 1475 4592 1144 1915 8468 17849 119 1284 1208 1437 1115 26660 11356 1475 4035 25634 170 102\n",
      "[NeMo I 2021-10-05 12:37:39 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2021-10-05 12:37:39 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2021-10-05 12:37:39 text_classification_dataset:244] label: 0\n",
      "[NeMo I 2021-10-05 12:37:39 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2021-10-05 12:37:39 text_classification_dataset:239] example 1: ['Ovarian', 'cancer', 'risk', 'in', 'BRCA1', 'carriers', 'is', 'modified', 'by', 'the', 'HRAS1', 'variable', 'number', 'of', 'tandem', 'repeat', '(VNTR)', 'locus.', 'Women', 'who', 'carry', 'a', 'mutation', 'in', 'the', 'BRCA1', 'gene', '(', 'on', 'chromosome', '17q21', ')', ',', 'have', 'an', '80', '%', 'risk', 'of', 'breast', 'cancer', 'and', 'a', '40', '%', 'risk', 'of', 'ovarian', 'cancer', 'by', 'the', 'age', 'of', '70', '(', 'ref', '.', '1', ')', '.', 'The', 'variable', 'penetrance', 'of', 'BRCA1', 'suggests', 'that', 'other', 'genetic', 'and', 'non-genetic', 'factors', 'play', 'a', 'role', 'in', 'tumourigenesis', 'in', 'these', 'individuals', '.', 'The', 'HRAS1', 'variable', 'number', 'of', 'tandem', 'repeats', '(', 'VNTR', ')', 'polymorphism', ',', 'located', '1', 'kilobase', '(', 'kb', ')', 'downstream', 'of', 'the', 'HRAS1', 'proto-oncogene', '(', 'chromosome', '11p15', '.', '5', ')', 'is', 'one', 'possible', 'genetic', 'modifier', 'of', 'cancer', 'penetrance', '.', 'Individuals', 'who', 'have', 'rare', 'alleles', 'of', 'the', 'VNTR', 'have', 'an', 'increased', 'risk', 'of', 'certain', 'types', 'of', 'cancers', ',', 'including', 'breast', 'cancer', '(', '2-4', ')', '.', 'To', 'investigate', 'whether', 'the', 'presence', 'of', 'rare', 'HRAS1', 'alleles', 'increases', 'susceptibility', 'to', 'hereditary', 'breast', 'and', 'ovarian', 'cancer', ',', 'we', 'have', 'typed', 'a', 'panel', 'of', '307', 'female', 'BRCA1', 'carriers', 'at', 'this', 'locus', 'using', 'a', 'PCR-based', 'technique', '.', 'The', 'risk', 'for', 'ovarian', 'cancer', 'was', '2', '.', '11', 'times', 'greater', 'for', 'BRCA1', 'carriers', 'harbouring', 'one', 'or', 'two', 'rare', 'HRAS1', 'alleles', ',', 'compared', 'to', 'carriers', 'with', 'only', 'common', 'alleles', '(', 'P', '=', '0', '.', '015', ')', '.', 'The', 'magnitude', 'of', 'the', 'relative', 'risk', 'associated', 'with', 'a', 'rare', 'HRAS1', 'allele', 'was', 'not', 'altered', 'by', 'adjusting', 'for', 'the', 'other', 'known', 'risk', 'factors', 'for', 'hereditary', 'ovarian', 'cancer', '(', '5', ')', '.', 'Susceptibility', 'to', 'breast', 'cancer', 'did', 'not', 'appear', 'to', 'be', 'affected', 'by', 'the', 'presence', 'of', 'rare', 'HRAS1', 'alleles', '.', 'This', 'study', 'is', 'the', 'first', 'to', 'show', 'the', 'effect', 'of', 'a', 'modifying', 'gene', 'on', 'the', 'penetrance', 'of', 'an', 'inherited', 'cancer', 'syndrome']\n",
      "[NeMo I 2021-10-05 12:37:39 text_classification_dataset:240] subtokens: [CLS] O ##var ##ian cancer risk in BR ##CA ##1 carriers is modified by the H ##RA ##S ##1 variable number of tandem repeat ( V ##NT ##R ) lo ##cus . Women who carry a mutation in the BR ##CA ##1 gene ( on chromosome 17 ##q ##21 ) , have an 80 % risk of breast cancer and a 40 % risk [SEP]\n",
      "[NeMo I 2021-10-05 12:37:39 text_classification_dataset:241] input_ids: 101 152 8997 1811 4182 3187 1107 26660 11356 1475 11837 1110 5847 1118 1103 145 9664 1708 1475 7898 1295 1104 22090 9488 113 159 15681 2069 114 25338 6697 119 2453 1150 3564 170 17895 1107 1103 26660 11356 1475 5565 113 1113 18697 1542 4426 18202 114 117 1138 1126 2908 110 3187 1104 7209 4182 1105 170 1969 110 3187 102\n",
      "[NeMo I 2021-10-05 12:37:39 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2021-10-05 12:37:39 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2021-10-05 12:37:39 text_classification_dataset:244] label: 0\n",
      "[NeMo W 2021-10-05 12:37:40 text_classification_dataset:250] Found 100 out of 100 sentences with more than 64 subtokens. Truncated long sentences from the end.\n",
      "[NeMo I 2021-10-05 12:37:40 data_preprocessing:299] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2021-10-05 12:37:40 data_preprocessing:301] Min: 65 |                  Max: 65 |                  Mean: 65.0 |                  Median: 65.0\n",
      "[NeMo I 2021-10-05 12:37:40 data_preprocessing:307] 75 percentile: 65.00\n",
      "[NeMo I 2021-10-05 12:37:40 data_preprocessing:308] 99 percentile: 65.00\n",
      "[NeMo I 2021-10-05 12:37:40 text_classification_dataset:120] Read 10 examples from /dli/task/data/NCBI_tc-3/test_nemo_format.tsv.\n",
      "[NeMo I 2021-10-05 12:37:40 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2021-10-05 12:37:40 text_classification_dataset:239] example 0: ['Clustering', 'of', 'missense', 'mutations', 'in', 'the', 'ataxia-telangiectasia', 'gene', 'in', 'a', 'sporadic', 'T-cell', 'leukaemia.', 'Ataxia-telangiectasia', '(', 'A-T', ')', 'is', 'a', 'recessive', 'multi-system', 'disorder', 'caused', 'by', 'mutations', 'in', 'the', 'ATM', 'gene', 'at', '11q22-q23', '(', 'ref', '.', '3', ')', '.', 'The', 'risk', 'of', 'cancer', ',', 'especially', 'lymphoid', 'neoplasias', ',', 'is', 'substantially', 'elevated', 'in', 'A-T', 'patients', 'and', 'has', 'long', 'been', 'associated', 'with', 'chromosomal', 'instability', '.', 'By', 'analysing', 'tumour', 'DNA', 'from', 'patients', 'with', 'sporadic', 'T-cell', 'prolymphocytic', 'leukaemia', '(', 'T-PLL', ')', ',', 'a', 'rare', 'clonal', 'malignancy', 'with', 'similarities', 'to', 'a', 'mature', 'T-cell', 'leukaemia', 'seen', 'in', 'A-T', ',', 'we', 'demonstrate', 'a', 'high', 'frequency', 'of', 'ATM', 'mutations', 'in', 'T-PLL', '.', 'In', 'marked', 'contrast', 'to', 'the', 'ATM', 'mutation', 'pattern', 'in', 'A-T', ',', 'the', 'most', 'frequent', 'nucleotide', 'changes', 'in', 'this', 'leukaemia', 'were', 'missense', 'mutations', '.', 'These', 'clustered', 'in', 'the', 'region', 'corresponding', 'to', 'the', 'kinase', 'domain', ',', 'which', 'is', 'highly', 'conserved', 'in', 'ATM-related', 'proteins', 'in', 'mouse', ',', 'yeast', 'and', 'Drosophila', '.', 'The', 'resulting', 'amino-acid', 'substitutions', 'are', 'predicted', 'to', 'interfere', 'with', 'ATP', 'binding', 'or', 'substrate', 'recognition', '.', 'Two', 'of', 'seventeen', 'mutated', 'T-PLL', 'samples', 'had', 'a', 'previously', 'reported', 'A-T', 'allele', '.', 'In', 'contrast', ',', 'no', 'mutations', 'were', 'detected', 'in', 'the', 'p53', 'gene', ',', 'suggesting', 'that', 'this', 'tumour', 'suppressor', 'is', 'not', 'frequently', 'altered', 'in', 'this', 'leukaemia', '.', 'Occasional', 'missense', 'mutations', 'in', 'ATM', 'were', 'also', 'found', 'in', 'tumour', 'DNA', 'from', 'patients', 'with', 'B-cell', 'non-Hodgkins', 'lymphomas', '(', 'B-NHL', ')', 'and', 'a', 'B-NHL', 'cell', 'line', '.', 'The', 'evidence', 'of', 'a', 'significant', 'proportion', 'of', 'loss-of-function', 'mutations', 'and', 'a', 'complete', 'absence', 'of', 'the', 'normal', 'copy', 'of', 'ATM', 'in', 'the', 'majority', 'of', 'mutated', 'tumours', 'establishes', 'somatic', 'inactivation', 'of', 'this', 'gene', 'in', 'the', 'pathogenesis', 'of', 'sporadic', 'T-PLL', 'and', 'suggests', 'that', 'ATM', 'acts', 'as', 'a', 'tumour', 'suppressor', '.', 'As', 'constitutional', 'DNA', 'was', 'not', 'available', ',', 'a', 'putative', 'hereditary', 'predisposition', 'to', 'T-PLL', 'will', 'require', 'further', 'investigation', '.', '.']\n",
      "[NeMo I 2021-10-05 12:37:40 text_classification_dataset:240] subtokens: [CLS] C ##luster ##ing of miss ##ense mutations in the at ##ax ##ia - te ##lang ##ie ##ct ##asi ##a gene in a s ##poradic T - cell le ##uka ##emia . At ##ax ##ia - te ##lang ##ie ##ct ##asi ##a ( A - T ) is a re ##cess ##ive multi - system disorder caused by mutations in the AT ##M gene [SEP]\n",
      "[NeMo I 2021-10-05 12:37:40 text_classification_dataset:241] input_ids: 101 140 23225 1158 1104 5529 22615 17157 1107 1103 1120 7897 1465 118 21359 19514 1663 5822 17506 1161 5565 1107 170 188 27695 157 118 2765 5837 12658 20504 119 1335 7897 1465 118 21359 19514 1663 5822 17506 1161 113 138 118 157 114 1110 170 1231 22371 2109 4321 118 1449 8936 2416 1118 17157 1107 1103 13020 2107 5565 102\n",
      "[NeMo I 2021-10-05 12:37:40 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2021-10-05 12:37:40 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2021-10-05 12:37:40 text_classification_dataset:244] label: 0\n",
      "[NeMo I 2021-10-05 12:37:40 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2021-10-05 12:37:40 text_classification_dataset:239] example 1: ['Myotonic', 'dystrophy', 'protein', 'kinase', 'is', 'involved', 'in', 'the', 'modulation', 'of', 'the', 'Ca2+', 'homeostasis', 'in', 'skeletal', 'muscle', 'cells.', 'Myotonic', 'dystrophy', '(', 'DM', ')', ',', 'the', 'most', 'prevalent', 'muscular', 'disorder', 'in', 'adults', ',', 'is', 'caused', 'by', '(', 'CTG', ')', 'n-repeat', 'expansion', 'in', 'a', 'gene', 'encoding', 'a', 'protein', 'kinase', '(', 'DM', 'protein', 'kinase', ';', 'DMPK', ')', 'and', 'involves', 'changes', 'in', 'cytoarchitecture', 'and', 'ion', 'homeostasis', '.', 'To', 'obtain', 'clues', 'to', 'the', 'normal', 'biological', 'role', 'of', 'DMPK', 'in', 'cellular', 'ion', 'homeostasis', ',', 'we', 'have', 'compared', 'the', 'resting', '[', 'Ca2', '+', ']', 'i', ',', 'the', 'amplitude', 'and', 'shape', 'of', 'depolarization-induced', 'Ca2', '+', 'transients', ',', 'and', 'the', 'content', 'of', 'ATP-driven', 'ion', 'pumps', 'in', 'cultured', 'skeletal', 'muscle', 'cells', 'of', 'wild-type', 'and', 'DMPK', '[', '-', '/', '-', ']', 'knockout', 'mice', '.', 'In', 'vitro-differentiated', 'DMPK', '[', '-', '/', '-', ']', 'myotubes', 'exhibit', 'a', 'higher', 'resting', '[', 'Ca2', '+', ']', 'i', 'than', 'do', 'wild-type', 'myotubes', 'because', 'of', 'an', 'altered', 'open', 'probability', 'of', 'voltage-dependent', 'l-type', 'Ca2', '+', 'and', 'Na', '+', 'channels', '.', 'The', 'mutant', 'myotubes', 'exhibit', 'smaller', 'and', 'slower', 'Ca2', '+', 'responses', 'upon', 'triggering', 'by', 'acetylcholine', 'or', 'high', 'external', 'K', '+', '.', 'In', 'addition', ',', 'we', 'observed', 'that', 'these', 'Ca2', '+', 'transients', 'partially', 'result', 'from', 'an', 'influx', 'of', 'extracellular', 'Ca2', '+', 'through', 'the', 'l-type', 'Ca2', '+', 'channel', '.', 'Neither', 'the', 'content', 'nor', 'the', 'activity', 'of', 'Na', '+', '/', 'K', '+', 'ATPase', 'and', 'sarcoplasmic', 'reticulum', 'Ca2', '+', '-ATPase', 'are', 'affected', 'by', 'DMPK', 'absence', '.', 'In', 'conclusion', ',', 'our', 'data', 'suggest', 'that', 'DMPK', 'is', 'involved', 'in', 'modulating', 'the', 'initial', 'events', 'of', 'excitation-contraction', 'coupling', 'in', 'skeletal', 'muscle', '.', '.']\n",
      "[NeMo I 2021-10-05 12:37:40 text_classification_dataset:240] subtokens: [CLS] My ##oto ##nic d ##ys ##tro ##phy protein kinase is involved in the m ##od ##ulation of the C ##a ##2 + home ##ost ##asis in skeletal muscle cells . My ##oto ##nic d ##ys ##tro ##phy ( D ##M ) , the most prevalent muscular disorder in adults , is caused by ( CT ##G ) n - repeat expansion in a [SEP]\n",
      "[NeMo I 2021-10-05 12:37:40 text_classification_dataset:241] input_ids: 101 1422 12355 7770 173 6834 8005 22192 4592 24779 1110 2017 1107 1103 182 5412 6856 1104 1103 140 1161 1477 116 1313 15540 14229 1107 23400 6484 3652 119 1422 12355 7770 173 6834 8005 22192 113 141 2107 114 117 1103 1211 15950 14310 8936 1107 6323 117 1110 2416 1118 113 16899 2349 114 183 118 9488 4298 1107 170 102\n",
      "[NeMo I 2021-10-05 12:37:40 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2021-10-05 12:37:40 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2021-10-05 12:37:40 text_classification_dataset:244] label: 1\n",
      "[NeMo W 2021-10-05 12:37:40 text_classification_dataset:250] Found 10 out of 10 sentences with more than 64 subtokens. Truncated long sentences from the end.\n",
      "[NeMo I 2021-10-05 12:37:40 data_preprocessing:299] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2021-10-05 12:37:40 data_preprocessing:301] Min: 65 |                  Max: 65 |                  Mean: 65.0 |                  Median: 65.0\n",
      "[NeMo I 2021-10-05 12:37:40 data_preprocessing:307] 75 percentile: 65.00\n",
      "[NeMo I 2021-10-05 12:37:40 data_preprocessing:308] 99 percentile: 65.00\n",
      "[NeMo W 2021-10-05 12:37:40 modelPT:197] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact forit has already been registered.\n",
      "[NeMo W 2021-10-05 12:37:40 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/nemo/core/classes/modelPT.py:243: UserWarning: update_node() is deprecated, use OmegaConf.update(). (Since 2.0)\n",
      "      self.cfg.update_node(config_path, return_path)\n",
      "    \n",
      "[NeMo I 2021-10-05 12:37:40 megatron_utils:274] Downloading from https://api.ngc.nvidia.com/v2/models/nvidia/megatron_bert_345m/versions/v0.1_cased/files/release/mp_rank_00/model_optim_rng.pt\n",
      "Epoch 3:  85%|▊| 22/26 [00:04<00:00,  4.73it/s, loss=0.2, v_num=7-31, lr=1.21e-5\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  92%|▉| 24/26 [00:04<00:00,  4.97it/s, loss=0.2, v_num=7-31, lr=1.21e-5\u001b[A\n",
      "Epoch 3: 100%|█| 26/26 [00:04<00:00,  5.26it/s, loss=0.2, v_num=7-31, lr=1.21e-5\u001b[A[NeMo I 2021-10-05 12:39:50 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             91.18      96.88      93.94         32\n",
      "    label_id: 1                                             91.30      87.50      89.36         24\n",
      "    label_id: 2                                             93.02      90.91      91.95         44\n",
      "    -------------------\n",
      "    micro avg                                               92.00      92.00      92.00        100\n",
      "    macro avg                                               91.83      91.76      91.75        100\n",
      "    weighted avg                                            92.02      92.00      91.97        100\n",
      "    \n",
      "Epoch 3: 100%|█| 26/26 [00:05<00:00,  5.17it/s, loss=0.2, v_num=7-31, lr=1.16e-5\n",
      "                                                                                \u001b[AEpoch 3, global step 87: val_loss reached 0.18396 (best 0.18396), saving model to \"/dli/task/nemo_experiments/TextClassification/2021-10-05_12-37-31/checkpoints/TextClassification--val_loss=0.18-epoch=3.ckpt\" as top 3\n",
      "Epoch 4:  85%|▊| 22/26 [00:06<00:01,  3.18it/s, loss=0.138, v_num=7-31, lr=1.01e\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  92%|▉| 24/26 [00:07<00:00,  3.38it/s, loss=0.138, v_num=7-31, lr=1.01e\u001b[A\n",
      "Epoch 4: 100%|█| 26/26 [00:07<00:00,  3.61it/s, loss=0.138, v_num=7-31, lr=1.01e\u001b[A[NeMo I 2021-10-05 12:40:26 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             91.18      96.88      93.94         32\n",
      "    label_id: 1                                             91.30      87.50      89.36         24\n",
      "    label_id: 2                                             93.02      90.91      91.95         44\n",
      "    -------------------\n",
      "    micro avg                                               92.00      92.00      92.00        100\n",
      "    macro avg                                               91.83      91.76      91.75        100\n",
      "    weighted avg                                            92.02      92.00      91.97        100\n",
      "    \n",
      "Epoch 4: 100%|█| 26/26 [00:07<00:00,  3.57it/s, loss=0.138, v_num=7-31, lr=5.05e\n",
      "                                                                                \u001b[AEpoch 4, global step 109: val_loss reached 0.19265 (best 0.18396), saving model to \"/dli/task/nemo_experiments/TextClassification/2021-10-05_12-37-31/checkpoints/TextClassification--val_loss=0.19-epoch=4.ckpt\" as top 3\n",
      "Epoch 4: 100%|█| 26/26 [00:22<00:00,  1.17it/s, loss=0.138, v_num=7-31, lr=5.05eSaving latest checkpoint...\n",
      "Epoch 4: 100%|█| 26/26 [00:38<00:00,  1.48s/it, loss=0.138, v_num=7-31, lr=5.05e\n",
      "[NeMo W 2021-10-05 12:40:57 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/nemo/core/classes/modelPT.py:308: UserWarning: update_node() is deprecated, use OmegaConf.update(). (Since 2.0)\n",
      "      conf.update_node(conf_path, item.path)\n",
      "    \n",
      "[NeMo I 2021-10-05 12:42:13 text_classification_with_bert:121] Training finished!\n",
      "[NeMo I 2021-10-05 12:42:13 text_classification_with_bert:122] ===========================================================================================\n",
      "[NeMo I 2021-10-05 12:43:24 text_classification_with_bert:127] Model is saved into `.nemo` file: text_classification_model.nemo\n",
      "[NeMo I 2021-10-05 12:43:24 text_classification_with_bert:131] ===========================================================================================\n",
      "[NeMo I 2021-10-05 12:43:24 text_classification_with_bert:132] Starting the testing of the trained model on test set...\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Testing: 100%|████████████████████████████████████| 1/1 [00:00<00:00,  4.65it/s][NeMo I 2021-10-05 12:43:25 text_classification_model:165] test_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                            100.00      75.00      85.71          4\n",
      "    label_id: 1                                            100.00     100.00     100.00          2\n",
      "    label_id: 2                                             80.00     100.00      88.89          4\n",
      "    -------------------\n",
      "    micro avg                                               90.00      90.00      90.00         10\n",
      "    macro avg                                               93.33      91.67      91.53         10\n",
      "    weighted avg                                            92.00      90.00      89.84         10\n",
      "    \n",
      "Testing: 100%|████████████████████████████████████| 1/1 [00:00<00:00,  3.61it/s]\n",
      "[NeMo I 2021-10-05 12:43:25 text_classification_with_bert:134] Testing finished!\n",
      "[NeMo I 2021-10-05 12:43:25 text_classification_with_bert:135] ===========================================================================================\n",
      "[NeMo I 2021-10-05 12:43:25 text_classification_with_bert:139] ===========================================================================================\n",
      "[NeMo I 2021-10-05 12:43:25 text_classification_with_bert:140] Starting the inference on some sample queries...\n",
      "[NeMo I 2021-10-05 12:43:25 text_classification_with_bert:144] The prediction results of some sample queries with the trained model:\n",
      "[NeMo I 2021-10-05 12:43:25 text_classification_with_bert:146] Query : In contrast no mutations were detected in the p53 gene suggesting that this tumour suppressor is not frequently altered in this leukaemia\n",
      "[NeMo I 2021-10-05 12:43:25 text_classification_with_bert:147] Predicted label: 0\n",
      "[NeMo I 2021-10-05 12:43:25 text_classification_with_bert:146] Query : The first predictive testing for Huntington disease  was based on analysis of linked polymorphic DNA markers to estimate the likelihood of inheriting the mutation for HD\n",
      "[NeMo I 2021-10-05 12:43:25 text_classification_with_bert:147] Predicted label: 1\n",
      "[NeMo I 2021-10-05 12:43:25 text_classification_with_bert:146] Query : Further studies suggested that low dilutions of C5D serum contain a factor or factors interfering at some step in the hemolytic assay of C5 rather than a true C5 inhibitor or inactivator\n",
      "[NeMo I 2021-10-05 12:43:25 text_classification_with_bert:147] Predicted label: 2\n",
      "[NeMo I 2021-10-05 12:43:25 text_classification_with_bert:149] Inference finished!\n",
      "[NeMo I 2021-10-05 12:43:25 text_classification_with_bert:150] ===========================================================================================\n",
      "CPU times: user 9.55 s, sys: 3.58 s, total: 13.1 s\n",
      "Wall time: 6min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# TODO Try your own experiment with a different language model!\n",
    "\n",
    "\n",
    "# The training takes about____ to run\n",
    "\n",
    "TC_DIR = \"/dli/task/nemo/examples/nlp/text_classification\"\n",
    "\n",
    "# set the values we want to override\n",
    "NUM_CLASSES = 3\n",
    "MAX_SEQ_LENGTH = 64\n",
    "PATH_TO_TRAIN_FILE = \"/dli/task/data/NCBI_tc-3/train_nemo_format.tsv\"\n",
    "PATH_TO_VAL_FILE = \"/dli/task/data/NCBI_tc-3/dev_nemo_format.tsv\"\n",
    "PATH_TO_TEST_FILE = \"/dli/task/data/NCBI_tc-3/test_nemo_format.tsv\"\n",
    "# disease domain inference sample answers should be 0, 1, 2 \n",
    "INFER_SAMPLES_0 = \"In contrast no mutations were detected in the p53 gene suggesting that this tumour suppressor is not frequently altered in this leukaemia \"\n",
    "INFER_SAMPLES_1 = \"The first predictive testing for Huntington disease  was based on analysis of linked polymorphic DNA markers to estimate the likelihood of inheriting the mutation for HD\"\n",
    "INFER_SAMPLES_2 = \"Further studies suggested that low dilutions of C5D serum contain a factor or factors interfering at some step in the hemolytic assay of C5 rather than a true C5 inhibitor or inactivator\"\n",
    "MAX_EPOCHS = 5\n",
    "AMP_LEVEL = 'O1'\n",
    "PRECISION = 16\n",
    "LR = 5.0e-05\n",
    "PRETRAINED_MODEL_NAME = 'megatron-bert-345m-cased'\n",
    "BATCH_SIZE = 32\n",
    "# Override the config values in the command line\n",
    "!python $TC_DIR/text_classification_with_bert.py \\\n",
    "        model.dataset.num_classes=$NUM_CLASSES \\\n",
    "        model.dataset.max_seq_length=$MAX_SEQ_LENGTH \\\n",
    "        model.train_ds.file_path=$PATH_TO_TRAIN_FILE \\\n",
    "        model.validation_ds.file_path=$PATH_TO_VAL_FILE \\\n",
    "        model.test_ds.file_path=$PATH_TO_TEST_FILE \\\n",
    "        model.train_ds.batch_size=$BATCH_SIZE \\\n",
    "        model.validation_ds.batch_size=$BATCH_SIZE \\\n",
    "        model.test_ds.batch_size=$BATCH_SIZE \\\n",
    "        model.infer_samples=[\"$INFER_SAMPLES_0\",\"$INFER_SAMPLES_1\",\"$INFER_SAMPLES_2\"] \\\n",
    "        trainer.max_epochs=$MAX_EPOCHS \\\n",
    "        trainer.amp_level=$AMP_LEVEL \\\n",
    "        trainer.precision=$PRECISION \\\n",
    "        model.optim.lr=$LR \\\n",
    "        model.language_model.pretrained_model_name=$PRETRAINED_MODEL_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2.3 PyTorch Lightning Model and Trainer Workflow\n",
    "The NeMo model script is the quickest way to get up and running.  Sometimes, though, you may want to create your own script or work through your project in a more customized manner.  In that case, you can step through the PyTorch Lightning workflow, which is otherwise abstracted (encapsulated and hidden) within the model training script. We'll take a look at the script, then try working through the same workflow from scratch without the script or Hydra.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.1 Script Key Features\n",
    "You can open the [text_classification_with_bert.py](nemo/examples/nlp/text_classification/text_classification_with_bert.py) script to see exactly what is happening.  \n",
    "\n",
    "Here's an abbreviated version with logging and initial comments removed:\n",
    "\n",
    "```python\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "from nemo.collections.nlp.models.text_classification import TextClassificationModel\n",
    "from nemo.collections.nlp.parts.nlp_overrides import NLPDDPPlugin\n",
    "from nemo.core.config import hydra_runner\n",
    "from nemo.utils.exp_manager import exp_manager\n",
    "\n",
    "\n",
    "@hydra_runner(config_path=\"conf\", config_name=\"text_classification_config\")\n",
    "def main(cfg: DictConfig) -> None:\n",
    "    trainer = pl.Trainer(plugins=[NLPDDPPlugin()], **cfg.trainer)\n",
    "    exp_manager(trainer, cfg.get(\"exp_manager\", None))\n",
    "\n",
    "    if not cfg.model.train_ds.file_path:\n",
    "        raise ValueError(\"'train_ds.file_path' need to be set for the training!\")\n",
    "\n",
    "    model = TextClassificationModel(cfg.model, trainer=trainer)\n",
    "    trainer.fit(model)\n",
    "\n",
    "    if cfg.model.nemo_path:\n",
    "        # '.nemo' file contains the last checkpoint and the params to initialize the model\n",
    "        model.save_to(cfg.model.nemo_path)\n",
    "\n",
    "    # We evaluate the trained model on the test set if test_ds is set in the config file\n",
    "    if cfg.model.test_ds.file_path:\n",
    "        trainer.test(model=model, ckpt_path=None, verbose=False)\n",
    "\n",
    "    # perform inference on a list of queries.\n",
    "    if \"infer_samples\" in cfg.model and cfg.model.infer_samples:       \n",
    "        # max_seq_length=512 is the maximum length BERT supports.\n",
    "        results = model.classifytext(queries=cfg.model.infer_samples, batch_size=16, max_seq_length=512)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "```\n",
    "The Hydra decorator, `@hydra_runner`, connects the configuration file and provides the mechanism for the command line overrides. \n",
    "\n",
    "Once the configuration is established, the key steps are:\n",
    "1. Instantiate the trainer with `trainer = pl.Trainer(plugins=[NLPDDPPlugin()], **cfg.trainer)`\n",
    "1. Instantiate the model with `model = TextClassificationModel(cfg.model, trainer=trainer)`\n",
    "1. Train the model with `trainer.fit(model)`\n",
    "\n",
    "Additional steps for optional inference and evaluation are:\n",
    "* Evaluate with `trainer.test(model=model, ckpt_path=None, verbose=False)`\n",
    "* Infer with `results = model.classifytext(queries=cfg.model.infer_samples, batch_size=16, max_seq_length=512)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.3.2 Model Training from Scratch\n",
    "Execute the following cell to restart the notebook kernel to clear variables and GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restart the kernel\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the `nemo_nlp` collection, the experiment manager, PyTorch Lightning, and OmegaConf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections import nlp as nemo_nlp\n",
    "from nemo.utils.exp_manager import exp_manager\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running these training steps manually without the script or Hydra, the correct configuration must be set prior to instantiation.  We've already determined the changes we want to make to the config file for this project.  Previously, we used the Hydra override feature in the command line, but those changes are made this time using `OmegaConf`. The syntax looks similar, except this time we are directly changing the `OmegaConf` object, `config`, in Python, and will pass that object to `trainer`, `exp_manager`, and `model`.\n",
    "\n",
    "The default language model is `bert-base-uncased`.  To override it, add to the cell (for example):\n",
    "```python\n",
    "    PRETRAINED_MODEL_NAME = 'bert-base-cased'\n",
    "    config.model.language_model.pretrained_model_name=PRETRAINED_MODEL_NAME\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the OmegaConf object by loading the config file\n",
    "TC_DIR = \"/dli/task/nemo/examples/nlp/text_classification\"\n",
    "CONFIG_FILE = \"text_classification_config.yaml\"\n",
    "config = OmegaConf.load(TC_DIR + \"/conf/\" + CONFIG_FILE)\n",
    "\n",
    "# set the values we want to change\n",
    "NUM_CLASSES = 3\n",
    "MAX_SEQ_LENGTH = 128\n",
    "PATH_TO_TRAIN_FILE = \"/dli/task/data/NCBI_tc-3/train_nemo_format.tsv\"\n",
    "PATH_TO_VAL_FILE = \"/dli/task/data/NCBI_tc-3/dev_nemo_format.tsv\"\n",
    "PATH_TO_TEST_FILE = \"/dli/task/data/NCBI_tc-3/test_nemo_format.tsv\"\n",
    "# disease domain inference sample answers should be 0, 1, 2 \n",
    "INFER_SAMPLES = [\"Germline mutations in BRCA1 are responsible for most cases of inherited breast and ovarian cancer \",\n",
    "        \"The first predictive testing for Huntington disease  was based on analysis of linked polymorphic DNA markers to estimate the likelihood of inheriting the mutation for HD\",\n",
    "        \"Further studies suggested that low dilutions of C5D serum contain a factor or factors interfering at some step in the hemolytic assay of C5 rather than a true C5 inhibitor or inactivator\"\n",
    "        ]\n",
    "MAX_EPOCHS = 5\n",
    "AMP_LEVEL = 'O1'\n",
    "PRECISION = 16\n",
    "LR = 5.0e-05\n",
    "\n",
    "# set the config values using omegaconf\n",
    "config.model.dataset.num_classes = NUM_CLASSES\n",
    "config.model.dataset.max_seq_length = MAX_SEQ_LENGTH\n",
    "config.model.train_ds.file_path = PATH_TO_TRAIN_FILE\n",
    "config.model.validation_ds.file_path = PATH_TO_VAL_FILE\n",
    "config.model.test_ds.file_path = PATH_TO_TEST_FILE\n",
    "config.model.infer_samples = INFER_SAMPLES\n",
    "config.trainer.max_epochs = MAX_EPOCHS\n",
    "config.trainer.amp_level = AMP_LEVEL\n",
    "config.trainer.precision = PRECISION\n",
    "config.model.optim.lr = LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that `config` has been updated with the correct values, instantiate the trainer and experiment manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Using native 16bit precision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-10-05 12:49:27 exp_manager:216] Experiments will be logged at /dli/task/nemo_experiments/TextClassification/2021-10-05_12-49-27\n",
      "[NeMo I 2021-10-05 12:49:27 exp_manager:563] TensorboardLogger has been set up\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/dli/task/nemo_experiments/TextClassification/2021-10-05_12-49-27')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the trainer and experiment manager\n",
    "trainer = pl.Trainer(**config.trainer)\n",
    "exp_manager(trainer, config.exp_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-10-05 12:49:57 text_classification_dataset:120] Read 683 examples from /dli/task/data/NCBI_tc-3/train_nemo_format.tsv.\n",
      "[NeMo I 2021-10-05 12:49:57 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2021-10-05 12:49:57 text_classification_dataset:239] example 0: ['Two', 'new', 'arylsulfatase', 'A', '(ARSA)', 'mutations', 'in', 'a', 'juvenile', 'metachromatic', 'leukodystrophy', '(MLD)', 'patient.', 'Fragments', 'of', 'the', 'arylsulfatase', 'A', '(', 'ARSA', ')', 'gene', 'from', 'a', 'patient', 'with', 'juvenile-onset', 'metachromatic', 'leukodystrophy', '(', 'MLD', ')', 'were', 'amplified', 'by', 'PCR', 'and', 'ligated', 'into', 'MP13', 'cloning', 'vectors', '.', 'Clones', 'hybridizing', 'with', 'cDNA', 'for', 'human', 'ARSA', 'were', 'selected', ',', 'examined', 'for', 'appropriate', 'size', 'inserts', ',', 'and', 'used', 'to', 'prepare', 'single-stranded', 'phage', 'DNA', '.', 'Examination', 'of', 'the', 'entire', 'coding', 'and', 'most', 'of', 'the', 'intronic', 'sequence', 'revealed', 'two', 'putative', 'disease-related', 'mutations', '.', 'One', ',', 'a', 'point', 'mutation', 'in', 'exon', '3', ',', 'resulted', 'in', 'the', 'substitution', 'of', 'isoleucine', 'by', 'serine', '.', 'Introduction', 'of', 'this', 'alteration', 'into', 'the', 'normal', 'ARSA', 'cDNA', 'sequence', 'resulted', 'in', 'a', 'substantial', 'decrease', 'in', 'ARSA', 'activity', 'on', 'transient', 'expression', 'in', 'cultured', 'baby', 'hamster', 'kidney', 'cells', '.', 'About', '5', '%', 'of', 'the', 'control', 'expression', 'was', 'observed', ',', 'suggesting', 'a', 'small', 'residual', 'activity', 'in', 'the', 'mutated', 'ARSA', '.', 'The', 'second', 'mutation', ',', 'a', 'G-to-A', 'transition', ',', 'occurred', 'in', 'the', 'other', 'allele', 'and', 'resulted', 'in', 'an', 'altered', 'splice-recognition', 'sequence', 'between', 'exon', '7', 'and', 'the', 'following', 'intron', '.', 'The', 'mutation', 'also', 'resulted', 'in', 'the', 'loss', 'of', 'a', 'restriction', 'site', '.', 'Apparently', 'normal', 'levels', 'of', 'mRNA', 'were', 'generated', 'from', 'this', 'allele', ',', 'but', 'no', 'ARSA', 'activity', 'or', 'immuno-cross-reactive', 'material', 'could', 'be', 'detected', '.', 'A', 'collection', 'of', 'DNA', 'samples', 'from', 'known', 'or', 'suspected', 'MLD', 'patients', ',', 'members', 'of', 'their', 'families', ',', 'and', 'normal', 'controls', 'was', 'screened', 'for', 'these', 'mutations', '.', 'Four', 'additional', 'individuals', 'carrying', 'each', 'of', 'the', 'mutations', 'were', 'found', 'among', 'the', 'nearly', '100', 'MLD', 'patients', 'in', 'the', 'sample', '.', 'Gene', 'segregation', 'in', 'the', 'original', 'patients', 'family', 'was', 'consistent', 'with', 'available', 'clinical', 'and', 'biochemical', 'data', '.', 'No', 'individuals', 'homozygous', 'for', 'either', 'of', 'these', 'two', 'mutations', 'were', 'identified', '.', 'However', ',', 'combinations', 'with', 'other', 'MLD', 'mutations', 'suggest', 'that', 'the', 'point', 'mutation', 'in', 'exon', '3', 'does', 'result', 'in', 'some', 'residual', 'enzyme', 'activity', 'and', 'is', 'associated', 'with', 'late-onset', 'forms', 'of', 'the', 'disease', '.', 'The', 'splice-site', 'mutation', 'following', 'exon', '7', 'produces', 'late-infantile', 'MLD', 'when', 'combined', 'with', 'other', 'enzyme-null', 'mutations', ',', 'implying', 'that', 'it', 'is', 'completely', 'silent', 'enzymatically', '.', '.']\n",
      "[NeMo I 2021-10-05 12:49:57 text_classification_dataset:240] subtokens: [CLS] two new ar ##yl ##sul ##fat ##ase a ( ars ##a ) mutations in a juvenile meta ##ch ##romatic le ##uk ##od ##yst ##rop ##hy ( ml ##d ) patient . fragments of the ar ##yl ##sul ##fat ##ase a ( ars ##a ) gene from a patient with juvenile - onset meta ##ch ##romatic le ##uk ##od ##yst ##rop ##hy ( ml ##d ) were amplified by pc ##r and liga ##ted into mp ##13 cl ##oning vectors . clones hybrid ##izing with cd ##na for human ars ##a were selected , examined for appropriate size insert ##s , and used to prepare single - stranded ph ##age dna . examination of the entire coding and most of the intro ##nic sequence revealed two put ##ative [SEP]\n",
      "[NeMo I 2021-10-05 12:49:57 text_classification_dataset:241] input_ids: 101 2048 2047 12098 8516 23722 27753 11022 1037 1006 29393 2050 1007 14494 1999 1037 11799 18804 2818 23645 3393 6968 7716 27268 18981 10536 1006 19875 2094 1007 5776 1012 10341 1997 1996 12098 8516 23722 27753 11022 1037 1006 29393 2050 1007 4962 2013 1037 5776 2007 11799 1011 14447 18804 2818 23645 3393 6968 7716 27268 18981 10536 1006 19875 2094 1007 2020 26986 2011 7473 2099 1998 8018 3064 2046 6131 17134 18856 13369 19019 1012 24418 8893 6026 2007 3729 2532 2005 2529 29393 2050 2020 3479 1010 8920 2005 6413 2946 19274 2015 1010 1998 2109 2000 7374 2309 1011 15577 6887 4270 6064 1012 7749 1997 1996 2972 16861 1998 2087 1997 1996 17174 8713 5537 3936 2048 2404 8082 102\n",
      "[NeMo I 2021-10-05 12:49:57 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2021-10-05 12:49:57 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2021-10-05 12:49:57 text_classification_dataset:244] label: 1\n",
      "[NeMo I 2021-10-05 12:49:57 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2021-10-05 12:49:57 text_classification_dataset:239] example 1: ['Further', 'investigation', 'of', 'the', 'HEXA', 'gene', 'intron', '9', 'donor', 'splice', 'site', 'mutation', 'frequently', 'found', 'in', 'non-Jewish', 'Tay-Sachs', 'disease', 'patients', 'from', 'the', 'British', 'Isles.', 'In', 'a', 'previous', 'study', 'we', 'found', 'that', 'a', 'Tay-Sachs', 'disease', '(', 'TSD', ')', 'causing', 'mutation', 'in', 'the', 'intron', '9', 'donor', 'splice', 'site', 'of', 'the', 'HEXA', 'gene', 'occurs', 'at', 'high', 'frequency', 'in', 'non-Jewish', 'patients', 'and', 'carriers', 'from', 'the', 'British', 'Isles', '.', 'It', 'was', 'found', 'more', 'frequently', 'in', 'subjects', 'of', 'Irish', ',', 'Scottish', ',', 'and', 'Welsh', 'origin', 'compared', 'with', 'English', 'origin', '(', '63', '%', 'and', '31', '%', 'respectively', ')', '.', 'We', 'have', 'now', 'tested', ',', 'in', 'a', 'blind', 'study', ',', '26', 'American', 'TSD', 'carriers', 'and', '28', 'non-carriers', 'who', 'have', 'British', 'ancestry', 'for', 'the', 'intron', '9', 'splice', 'site', 'mutation', '.', 'Six', 'of', 'the', 'carriers', 'and', 'none', 'of', 'the', 'controls', 'were', 'positive', 'for', 'the', 'mutation', '.', 'All', 'six', 'had', 'Irish', 'ancestry', ',', 'compared', 'with', 'nine', 'of', 'the', '20', 'other', '(', 'intron', '9', 'mutation', 'negative', ')', 'TSD', 'carriers', '(', 'p', '<', '0', '.', '05', ')', '.', 'These', 'results', 'confirm', 'the', 'previously', 'found', 'high', 'frequency', 'of', 'the', 'intron', '9', 'mutation', 'in', 'non-Jewish', 'TSD', 'families', 'of', 'British', 'Isles', ',', 'particularly', 'Irish', ',', 'origin', ',', 'and', 'reinforce', 'the', 'need', 'to', 'screen', 'such', 'families', 'for', 'this', 'mutation', '.']\n",
      "[NeMo I 2021-10-05 12:49:57 text_classification_dataset:240] subtokens: [CLS] further investigation of the he ##xa gene intro ##n 9 donor sp ##lice site mutation frequently found in non - jewish tay - sachs disease patients from the british isles . in a previous study we found that a tay - sachs disease ( ts ##d ) causing mutation in the intro ##n 9 donor sp ##lice site of the he ##xa gene occurs at high frequency in non - jewish patients and carriers from the british isles . it was found more frequently in subjects of irish , scottish , and welsh origin compared with english origin ( 63 % and 31 % respectively ) . we have now tested , in a blind study , 26 american ts ##d carriers and 28 non - carriers [SEP]\n",
      "[NeMo I 2021-10-05 12:49:57 text_classification_dataset:241] input_ids: 101 2582 4812 1997 1996 2002 18684 4962 17174 2078 1023 15009 11867 13231 2609 16221 4703 2179 1999 2512 1011 3644 28117 1011 22818 4295 5022 2013 1996 2329 14195 1012 1999 1037 3025 2817 2057 2179 2008 1037 28117 1011 22818 4295 1006 24529 2094 1007 4786 16221 1999 1996 17174 2078 1023 15009 11867 13231 2609 1997 1996 2002 18684 4962 5158 2012 2152 6075 1999 2512 1011 3644 5022 1998 11363 2013 1996 2329 14195 1012 2009 2001 2179 2062 4703 1999 5739 1997 3493 1010 4104 1010 1998 6124 4761 4102 2007 2394 4761 1006 6191 1003 1998 2861 1003 4414 1007 1012 2057 2031 2085 7718 1010 1999 1037 6397 2817 1010 2656 2137 24529 2094 11363 1998 2654 2512 1011 11363 102\n",
      "[NeMo I 2021-10-05 12:49:57 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2021-10-05 12:49:57 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2021-10-05 12:49:57 text_classification_dataset:244] label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2021-10-05 12:50:08 text_classification_dataset:250] Found 664 out of 683 sentences with more than 128 subtokens. Truncated long sentences from the end.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-10-05 12:50:08 data_preprocessing:299] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2021-10-05 12:50:08 data_preprocessing:301] Min: 74 |                  Max: 129 |                  Mean: 128.36163982430455 |                  Median: 129.0\n",
      "[NeMo I 2021-10-05 12:50:08 data_preprocessing:307] 75 percentile: 129.00\n",
      "[NeMo I 2021-10-05 12:50:08 data_preprocessing:308] 99 percentile: 129.00\n",
      "[NeMo I 2021-10-05 12:50:08 text_classification_dataset:120] Read 100 examples from /dli/task/data/NCBI_tc-3/dev_nemo_format.tsv.\n",
      "[NeMo I 2021-10-05 12:50:08 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2021-10-05 12:50:08 text_classification_dataset:239] example 0: ['BRCA1', 'is', 'secreted', 'and', 'exhibits', 'properties', 'of', 'a', 'granin.', 'Germline', 'mutations', 'in', 'BRCA1', 'are', 'responsible', 'for', 'most', 'cases', 'of', 'inherited', 'breast', 'and', 'ovarian', 'cancer', '.', 'However', ',', 'the', 'function', 'of', 'the', 'BRCA1', 'protein', 'has', 'remained', 'elusive', '.', 'We', 'now', 'show', 'that', 'BRCA1', 'encodes', 'a', '190-kD', 'protein', 'with', 'sequence', 'homology', 'and', 'biochemical', 'analogy', 'to', 'the', 'granin', 'protein', 'family', '.', 'Interestingly', ',', 'BRCA2', 'also', 'includes', 'a', 'motif', 'similar', 'to', 'the', 'granin', 'consensus', 'at', 'the', 'C', 'terminus', 'of', 'the', 'protein', '.', 'Both', 'BRCA1', 'and', 'the', 'granins', 'localize', 'to', 'secretory', 'vesicles', ',', 'are', 'secreted', 'by', 'a', 'regulated', 'pathway', ',', 'are', 'post-translationally', 'glycosylated', 'and', 'are', 'responsive', 'to', 'hormones', '.', 'As', 'a', 'regulated', 'secretory', 'protein', ',', 'BRCA1', 'appears', 'to', 'function', 'by', 'a', 'mechanism', 'not', 'previously', 'described', 'for', 'tumour', 'suppressor', 'gene', 'products', '.', '.']\n",
      "[NeMo I 2021-10-05 12:50:08 text_classification_dataset:240] subtokens: [CLS] br ##ca ##1 is secret ##ed and exhibits properties of a gran ##in . ge ##rm ##line mutations in br ##ca ##1 are responsible for most cases of inherited breast and o ##var ##ian cancer . however , the function of the br ##ca ##1 protein has remained elusive . we now show that br ##ca ##1 en ##codes a 190 - k ##d protein with sequence homo ##logy and bio ##chemical analogy to the gran ##in protein family . interesting ##ly , br ##ca ##2 also includes a motif similar to the gran ##in consensus at the c terminus of the protein . both br ##ca ##1 and the gran ##ins local ##ize to secret ##ory ve ##sic ##les , are secret ##ed by a regulated [SEP]\n",
      "[NeMo I 2021-10-05 12:50:08 text_classification_dataset:241] input_ids: 101 7987 3540 2487 2003 3595 2098 1998 10637 5144 1997 1037 12604 2378 1012 16216 10867 4179 14494 1999 7987 3540 2487 2024 3625 2005 2087 3572 1997 7900 7388 1998 1051 10755 2937 4456 1012 2174 1010 1996 3853 1997 1996 7987 3540 2487 5250 2038 2815 26475 1012 2057 2085 2265 2008 7987 3540 2487 4372 23237 1037 11827 1011 1047 2094 5250 2007 5537 24004 6483 1998 16012 15869 23323 2000 1996 12604 2378 5250 2155 1012 5875 2135 1010 7987 3540 2475 2036 2950 1037 16226 2714 2000 1996 12604 2378 10465 2012 1996 1039 7342 1997 1996 5250 1012 2119 7987 3540 2487 1998 1996 12604 7076 2334 4697 2000 3595 10253 2310 19570 4244 1010 2024 3595 2098 2011 1037 12222 102\n",
      "[NeMo I 2021-10-05 12:50:08 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2021-10-05 12:50:08 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2021-10-05 12:50:08 text_classification_dataset:244] label: 0\n",
      "[NeMo I 2021-10-05 12:50:08 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2021-10-05 12:50:08 text_classification_dataset:239] example 1: ['Ovarian', 'cancer', 'risk', 'in', 'BRCA1', 'carriers', 'is', 'modified', 'by', 'the', 'HRAS1', 'variable', 'number', 'of', 'tandem', 'repeat', '(VNTR)', 'locus.', 'Women', 'who', 'carry', 'a', 'mutation', 'in', 'the', 'BRCA1', 'gene', '(', 'on', 'chromosome', '17q21', ')', ',', 'have', 'an', '80', '%', 'risk', 'of', 'breast', 'cancer', 'and', 'a', '40', '%', 'risk', 'of', 'ovarian', 'cancer', 'by', 'the', 'age', 'of', '70', '(', 'ref', '.', '1', ')', '.', 'The', 'variable', 'penetrance', 'of', 'BRCA1', 'suggests', 'that', 'other', 'genetic', 'and', 'non-genetic', 'factors', 'play', 'a', 'role', 'in', 'tumourigenesis', 'in', 'these', 'individuals', '.', 'The', 'HRAS1', 'variable', 'number', 'of', 'tandem', 'repeats', '(', 'VNTR', ')', 'polymorphism', ',', 'located', '1', 'kilobase', '(', 'kb', ')', 'downstream', 'of', 'the', 'HRAS1', 'proto-oncogene', '(', 'chromosome', '11p15', '.', '5', ')', 'is', 'one', 'possible', 'genetic', 'modifier', 'of', 'cancer', 'penetrance', '.', 'Individuals', 'who', 'have', 'rare', 'alleles', 'of', 'the', 'VNTR', 'have', 'an', 'increased', 'risk', 'of', 'certain', 'types', 'of', 'cancers', ',', 'including', 'breast', 'cancer', '(', '2-4', ')', '.', 'To', 'investigate', 'whether', 'the', 'presence', 'of', 'rare', 'HRAS1', 'alleles', 'increases', 'susceptibility', 'to', 'hereditary', 'breast', 'and', 'ovarian', 'cancer', ',', 'we', 'have', 'typed', 'a', 'panel', 'of', '307', 'female', 'BRCA1', 'carriers', 'at', 'this', 'locus', 'using', 'a', 'PCR-based', 'technique', '.', 'The', 'risk', 'for', 'ovarian', 'cancer', 'was', '2', '.', '11', 'times', 'greater', 'for', 'BRCA1', 'carriers', 'harbouring', 'one', 'or', 'two', 'rare', 'HRAS1', 'alleles', ',', 'compared', 'to', 'carriers', 'with', 'only', 'common', 'alleles', '(', 'P', '=', '0', '.', '015', ')', '.', 'The', 'magnitude', 'of', 'the', 'relative', 'risk', 'associated', 'with', 'a', 'rare', 'HRAS1', 'allele', 'was', 'not', 'altered', 'by', 'adjusting', 'for', 'the', 'other', 'known', 'risk', 'factors', 'for', 'hereditary', 'ovarian', 'cancer', '(', '5', ')', '.', 'Susceptibility', 'to', 'breast', 'cancer', 'did', 'not', 'appear', 'to', 'be', 'affected', 'by', 'the', 'presence', 'of', 'rare', 'HRAS1', 'alleles', '.', 'This', 'study', 'is', 'the', 'first', 'to', 'show', 'the', 'effect', 'of', 'a', 'modifying', 'gene', 'on', 'the', 'penetrance', 'of', 'an', 'inherited', 'cancer', 'syndrome']\n",
      "[NeMo I 2021-10-05 12:50:08 text_classification_dataset:240] subtokens: [CLS] o ##var ##ian cancer risk in br ##ca ##1 carriers is modified by the hr ##as ##1 variable number of tandem repeat ( v ##nt ##r ) locus . women who carry a mutation in the br ##ca ##1 gene ( on chromosome 17 ##q ##21 ) , have an 80 % risk of breast cancer and a 40 % risk of o ##var ##ian cancer by the age of 70 ( ref . 1 ) . the variable pen ##et ##rance of br ##ca ##1 suggests that other genetic and non - genetic factors play a role in tu ##mour ##igen ##esis in these individuals . the hr ##as ##1 variable number of tandem repeats ( v ##nt ##r ) poly ##morphism , located 1 ki [SEP]\n",
      "[NeMo I 2021-10-05 12:50:08 text_classification_dataset:241] input_ids: 101 1051 10755 2937 4456 3891 1999 7987 3540 2487 11363 2003 6310 2011 1996 17850 3022 2487 8023 2193 1997 18231 9377 1006 1058 3372 2099 1007 25206 1012 2308 2040 4287 1037 16221 1999 1996 7987 3540 2487 4962 1006 2006 16706 2459 4160 17465 1007 1010 2031 2019 3770 1003 3891 1997 7388 4456 1998 1037 2871 1003 3891 1997 1051 10755 2937 4456 2011 1996 2287 1997 3963 1006 25416 1012 1015 1007 1012 1996 8023 7279 3388 21621 1997 7987 3540 2487 6083 2008 2060 7403 1998 2512 1011 7403 5876 2377 1037 2535 1999 10722 20360 29206 19009 1999 2122 3633 1012 1996 17850 3022 2487 8023 2193 1997 18231 17993 1006 1058 3372 2099 1007 26572 19539 1010 2284 1015 11382 102\n",
      "[NeMo I 2021-10-05 12:50:08 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2021-10-05 12:50:08 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2021-10-05 12:50:08 text_classification_dataset:244] label: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2021-10-05 12:50:10 text_classification_dataset:250] Found 99 out of 100 sentences with more than 128 subtokens. Truncated long sentences from the end.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-10-05 12:50:10 data_preprocessing:299] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2021-10-05 12:50:10 data_preprocessing:301] Min: 120 |                  Max: 129 |                  Mean: 128.91 |                  Median: 129.0\n",
      "[NeMo I 2021-10-05 12:50:10 data_preprocessing:307] 75 percentile: 129.00\n",
      "[NeMo I 2021-10-05 12:50:10 data_preprocessing:308] 99 percentile: 129.00\n",
      "[NeMo I 2021-10-05 12:50:10 text_classification_dataset:120] Read 10 examples from /dli/task/data/NCBI_tc-3/test_nemo_format.tsv.\n",
      "[NeMo I 2021-10-05 12:50:10 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2021-10-05 12:50:10 text_classification_dataset:239] example 0: ['Clustering', 'of', 'missense', 'mutations', 'in', 'the', 'ataxia-telangiectasia', 'gene', 'in', 'a', 'sporadic', 'T-cell', 'leukaemia.', 'Ataxia-telangiectasia', '(', 'A-T', ')', 'is', 'a', 'recessive', 'multi-system', 'disorder', 'caused', 'by', 'mutations', 'in', 'the', 'ATM', 'gene', 'at', '11q22-q23', '(', 'ref', '.', '3', ')', '.', 'The', 'risk', 'of', 'cancer', ',', 'especially', 'lymphoid', 'neoplasias', ',', 'is', 'substantially', 'elevated', 'in', 'A-T', 'patients', 'and', 'has', 'long', 'been', 'associated', 'with', 'chromosomal', 'instability', '.', 'By', 'analysing', 'tumour', 'DNA', 'from', 'patients', 'with', 'sporadic', 'T-cell', 'prolymphocytic', 'leukaemia', '(', 'T-PLL', ')', ',', 'a', 'rare', 'clonal', 'malignancy', 'with', 'similarities', 'to', 'a', 'mature', 'T-cell', 'leukaemia', 'seen', 'in', 'A-T', ',', 'we', 'demonstrate', 'a', 'high', 'frequency', 'of', 'ATM', 'mutations', 'in', 'T-PLL', '.', 'In', 'marked', 'contrast', 'to', 'the', 'ATM', 'mutation', 'pattern', 'in', 'A-T', ',', 'the', 'most', 'frequent', 'nucleotide', 'changes', 'in', 'this', 'leukaemia', 'were', 'missense', 'mutations', '.', 'These', 'clustered', 'in', 'the', 'region', 'corresponding', 'to', 'the', 'kinase', 'domain', ',', 'which', 'is', 'highly', 'conserved', 'in', 'ATM-related', 'proteins', 'in', 'mouse', ',', 'yeast', 'and', 'Drosophila', '.', 'The', 'resulting', 'amino-acid', 'substitutions', 'are', 'predicted', 'to', 'interfere', 'with', 'ATP', 'binding', 'or', 'substrate', 'recognition', '.', 'Two', 'of', 'seventeen', 'mutated', 'T-PLL', 'samples', 'had', 'a', 'previously', 'reported', 'A-T', 'allele', '.', 'In', 'contrast', ',', 'no', 'mutations', 'were', 'detected', 'in', 'the', 'p53', 'gene', ',', 'suggesting', 'that', 'this', 'tumour', 'suppressor', 'is', 'not', 'frequently', 'altered', 'in', 'this', 'leukaemia', '.', 'Occasional', 'missense', 'mutations', 'in', 'ATM', 'were', 'also', 'found', 'in', 'tumour', 'DNA', 'from', 'patients', 'with', 'B-cell', 'non-Hodgkins', 'lymphomas', '(', 'B-NHL', ')', 'and', 'a', 'B-NHL', 'cell', 'line', '.', 'The', 'evidence', 'of', 'a', 'significant', 'proportion', 'of', 'loss-of-function', 'mutations', 'and', 'a', 'complete', 'absence', 'of', 'the', 'normal', 'copy', 'of', 'ATM', 'in', 'the', 'majority', 'of', 'mutated', 'tumours', 'establishes', 'somatic', 'inactivation', 'of', 'this', 'gene', 'in', 'the', 'pathogenesis', 'of', 'sporadic', 'T-PLL', 'and', 'suggests', 'that', 'ATM', 'acts', 'as', 'a', 'tumour', 'suppressor', '.', 'As', 'constitutional', 'DNA', 'was', 'not', 'available', ',', 'a', 'putative', 'hereditary', 'predisposition', 'to', 'T-PLL', 'will', 'require', 'further', 'investigation', '.', '.']\n",
      "[NeMo I 2021-10-05 12:50:10 text_classification_dataset:240] subtokens: [CLS] cluster ##ing of miss ##ense mutations in the ata ##xia - tel ##ang ##iec ##tas ##ia gene in a sporadic t - cell le ##uka ##emia . ata ##xia - tel ##ang ##iec ##tas ##ia ( a - t ) is a recess ##ive multi - system disorder caused by mutations in the atm gene at 11 ##q ##22 - q ##23 ( ref . 3 ) . the risk of cancer , especially l ##ym ##ph ##oid neo ##pl ##asia ##s , is substantially elevated in a - t patients and has long been associated with ch ##rom ##osomal instability . by anal ##ys ##ing tu ##mour dna from patients with sporadic t - cell pro ##ly ##mp ##ho ##cy ##tic le ##uka ##emia ( t [SEP]\n",
      "[NeMo I 2021-10-05 12:50:10 text_classification_dataset:241] input_ids: 101 9324 2075 1997 3335 16700 14494 1999 1996 29533 14787 1011 10093 5654 23783 10230 2401 4962 1999 1037 24590 1056 1011 3526 3393 15750 17577 1012 29533 14787 1011 10093 5654 23783 10230 2401 1006 1037 1011 1056 1007 2003 1037 28290 3512 4800 1011 2291 8761 3303 2011 14494 1999 1996 27218 4962 2012 2340 4160 19317 1011 1053 21926 1006 25416 1012 1017 1007 1012 1996 3891 1997 4456 1010 2926 1048 24335 8458 9314 9253 24759 15396 2015 1010 2003 12381 8319 1999 1037 1011 1056 5022 1998 2038 2146 2042 3378 2007 10381 21716 27642 18549 1012 2011 20302 7274 2075 10722 20360 6064 2013 5022 2007 24590 1056 1011 3526 4013 2135 8737 6806 5666 4588 3393 15750 17577 1006 1056 102\n",
      "[NeMo I 2021-10-05 12:50:10 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2021-10-05 12:50:10 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2021-10-05 12:50:10 text_classification_dataset:244] label: 0\n",
      "[NeMo I 2021-10-05 12:50:10 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2021-10-05 12:50:10 text_classification_dataset:239] example 1: ['Myotonic', 'dystrophy', 'protein', 'kinase', 'is', 'involved', 'in', 'the', 'modulation', 'of', 'the', 'Ca2+', 'homeostasis', 'in', 'skeletal', 'muscle', 'cells.', 'Myotonic', 'dystrophy', '(', 'DM', ')', ',', 'the', 'most', 'prevalent', 'muscular', 'disorder', 'in', 'adults', ',', 'is', 'caused', 'by', '(', 'CTG', ')', 'n-repeat', 'expansion', 'in', 'a', 'gene', 'encoding', 'a', 'protein', 'kinase', '(', 'DM', 'protein', 'kinase', ';', 'DMPK', ')', 'and', 'involves', 'changes', 'in', 'cytoarchitecture', 'and', 'ion', 'homeostasis', '.', 'To', 'obtain', 'clues', 'to', 'the', 'normal', 'biological', 'role', 'of', 'DMPK', 'in', 'cellular', 'ion', 'homeostasis', ',', 'we', 'have', 'compared', 'the', 'resting', '[', 'Ca2', '+', ']', 'i', ',', 'the', 'amplitude', 'and', 'shape', 'of', 'depolarization-induced', 'Ca2', '+', 'transients', ',', 'and', 'the', 'content', 'of', 'ATP-driven', 'ion', 'pumps', 'in', 'cultured', 'skeletal', 'muscle', 'cells', 'of', 'wild-type', 'and', 'DMPK', '[', '-', '/', '-', ']', 'knockout', 'mice', '.', 'In', 'vitro-differentiated', 'DMPK', '[', '-', '/', '-', ']', 'myotubes', 'exhibit', 'a', 'higher', 'resting', '[', 'Ca2', '+', ']', 'i', 'than', 'do', 'wild-type', 'myotubes', 'because', 'of', 'an', 'altered', 'open', 'probability', 'of', 'voltage-dependent', 'l-type', 'Ca2', '+', 'and', 'Na', '+', 'channels', '.', 'The', 'mutant', 'myotubes', 'exhibit', 'smaller', 'and', 'slower', 'Ca2', '+', 'responses', 'upon', 'triggering', 'by', 'acetylcholine', 'or', 'high', 'external', 'K', '+', '.', 'In', 'addition', ',', 'we', 'observed', 'that', 'these', 'Ca2', '+', 'transients', 'partially', 'result', 'from', 'an', 'influx', 'of', 'extracellular', 'Ca2', '+', 'through', 'the', 'l-type', 'Ca2', '+', 'channel', '.', 'Neither', 'the', 'content', 'nor', 'the', 'activity', 'of', 'Na', '+', '/', 'K', '+', 'ATPase', 'and', 'sarcoplasmic', 'reticulum', 'Ca2', '+', '-ATPase', 'are', 'affected', 'by', 'DMPK', 'absence', '.', 'In', 'conclusion', ',', 'our', 'data', 'suggest', 'that', 'DMPK', 'is', 'involved', 'in', 'modulating', 'the', 'initial', 'events', 'of', 'excitation-contraction', 'coupling', 'in', 'skeletal', 'muscle', '.', '.']\n",
      "[NeMo I 2021-10-05 12:50:10 text_classification_dataset:240] subtokens: [CLS] my ##oton ##ic d ##yst ##rop ##hy protein kinase is involved in the modulation of the ca ##2 + home ##osta ##sis in skeletal muscle cells . my ##oton ##ic d ##yst ##rop ##hy ( d ##m ) , the most prevalent muscular disorder in adults , is caused by ( ct ##g ) n - repeat expansion in a gene encoding a protein kinase ( d ##m protein kinase ; d ##mp ##k ) and involves changes in cy ##to ##ar ##chi ##tec ##ture and ion home ##osta ##sis . to obtain clues to the normal biological role of d ##mp ##k in cellular ion home ##osta ##sis , we have compared the resting [ ca ##2 + ] i , the amplitude and shape of [SEP]\n",
      "[NeMo I 2021-10-05 12:50:10 text_classification_dataset:241] input_ids: 101 2026 25862 2594 1040 27268 18981 10536 5250 21903 2003 2920 1999 1996 25502 1997 1996 6187 2475 1009 2188 28696 6190 1999 20415 6740 4442 1012 2026 25862 2594 1040 27268 18981 10536 1006 1040 2213 1007 1010 1996 2087 15157 13472 8761 1999 6001 1010 2003 3303 2011 1006 14931 2290 1007 1050 1011 9377 4935 1999 1037 4962 17181 1037 5250 21903 1006 1040 2213 5250 21903 1025 1040 8737 2243 1007 1998 7336 3431 1999 22330 3406 2906 5428 26557 11244 1998 10163 2188 28696 6190 1012 2000 6855 15774 2000 1996 3671 6897 2535 1997 1040 8737 2243 1999 12562 10163 2188 28696 6190 1010 2057 2031 4102 1996 8345 1031 6187 2475 1009 1033 1045 1010 1996 22261 1998 4338 1997 102\n",
      "[NeMo I 2021-10-05 12:50:10 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2021-10-05 12:50:10 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2021-10-05 12:50:10 text_classification_dataset:244] label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2021-10-05 12:50:10 text_classification_dataset:250] Found 10 out of 10 sentences with more than 128 subtokens. Truncated long sentences from the end.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-10-05 12:50:10 data_preprocessing:299] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2021-10-05 12:50:10 data_preprocessing:301] Min: 129 |                  Max: 129 |                  Mean: 129.0 |                  Median: 129.0\n",
      "[NeMo I 2021-10-05 12:50:10 data_preprocessing:307] 75 percentile: 129.00\n",
      "[NeMo I 2021-10-05 12:50:10 data_preprocessing:308] 99 percentile: 129.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2021-10-05 12:50:10 modelPT:197] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact forit has already been registered.\n",
      "[NeMo W 2021-10-05 12:50:10 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/nemo/core/classes/modelPT.py:243: UserWarning: update_node() is deprecated, use OmegaConf.update(). (Since 2.0)\n",
      "      self.cfg.update_node(config_path, return_path)\n",
      "    \n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertEncoder: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model \n",
    "model = nemo_nlp.models.TextClassificationModel(config.model, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-10-05 12:50:14 modelPT:748] Optimizer config = Adam (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.999]\n",
      "        eps: 1e-08\n",
      "        lr: 5e-05\n",
      "        weight_decay: 0.01\n",
      "    )\n",
      "[NeMo I 2021-10-05 12:50:14 lr_scheduler:617] Scheduler \"<nemo.core.optim.lr_scheduler.WarmupAnnealing object at 0x7f7e511b7730>\" \n",
      "    will be used during training (effective maximum steps = 55) - \n",
      "    Parameters : \n",
      "    (warmup_steps: null\n",
      "    warmup_ratio: 0.1\n",
      "    last_epoch: -1\n",
      "    max_steps: 55\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "\n",
      "  | Name                  | Type                 | Params\n",
      "---------------------------------------------------------------\n",
      "0 | loss                  | CrossEntropyLoss     | 0     \n",
      "1 | bert_model            | BertEncoder          | 109 M \n",
      "2 | classifier            | SequenceClassifier   | 592 K \n",
      "3 | classification_report | ClassificationReport | 0     \n",
      "---------------------------------------------------------------\n",
      "110 M     Trainable params\n",
      "0         Non-trainable params\n",
      "110 M     Total params\n",
      "440.301   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c4a8ee22af4e35823b85d4e3b45ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-10-05 12:50:20 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                              0.00       0.00       0.00         32\n",
      "    label_id: 1                                              0.00       0.00       0.00         24\n",
      "    label_id: 2                                             44.00     100.00      61.11         44\n",
      "    -------------------\n",
      "    micro avg                                               44.00      44.00      44.00        100\n",
      "    macro avg                                               14.67      33.33      20.37        100\n",
      "    weighted avg                                            19.36      44.00      26.89        100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 10: val_loss reached 1.06308 (best 1.06308), saving model to \"/dli/task/nemo_experiments/TextClassification/2021-10-05_12-49-27/checkpoints/TextClassification--val_loss=1.06-epoch=0.ckpt\" as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-10-05 12:50:28 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                            100.00      78.12      87.72         32\n",
      "    label_id: 1                                              0.00       0.00       0.00         24\n",
      "    label_id: 2                                             58.67     100.00      73.95         44\n",
      "    -------------------\n",
      "    micro avg                                               69.00      69.00      69.00        100\n",
      "    macro avg                                               52.89      59.38      53.89        100\n",
      "    weighted avg                                            57.81      69.00      60.61        100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 21: val_loss reached 0.81228 (best 0.81228), saving model to \"/dli/task/nemo_experiments/TextClassification/2021-10-05_12-49-27/checkpoints/TextClassification--val_loss=0.81-epoch=1.ckpt\" as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-10-05 12:50:37 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             90.62      90.62      90.62         32\n",
      "    label_id: 1                                             75.00      50.00      60.00         24\n",
      "    label_id: 2                                             75.00      88.64      81.25         44\n",
      "    -------------------\n",
      "    micro avg                                               80.00      80.00      80.00        100\n",
      "    macro avg                                               80.21      76.42      77.29        100\n",
      "    weighted avg                                            80.00      80.00      79.15        100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 32: val_loss reached 0.62659 (best 0.62659), saving model to \"/dli/task/nemo_experiments/TextClassification/2021-10-05_12-49-27/checkpoints/TextClassification--val_loss=0.63-epoch=2.ckpt\" as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-10-05 12:50:45 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             87.88      90.62      89.23         32\n",
      "    label_id: 1                                             78.26      75.00      76.60         24\n",
      "    label_id: 2                                             86.36      86.36      86.36         44\n",
      "    -------------------\n",
      "    micro avg                                               85.00      85.00      85.00        100\n",
      "    macro avg                                               84.17      84.00      84.06        100\n",
      "    weighted avg                                            84.90      85.00      84.94        100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 43: val_loss reached 0.53359 (best 0.53359), saving model to \"/dli/task/nemo_experiments/TextClassification/2021-10-05_12-49-27/checkpoints/TextClassification--val_loss=0.53-epoch=3.ckpt\" as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-10-05 12:50:56 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             87.88      90.62      89.23         32\n",
      "    label_id: 1                                             79.17      79.17      79.17         24\n",
      "    label_id: 2                                             88.37      86.36      87.36         44\n",
      "    -------------------\n",
      "    micro avg                                               86.00      86.00      86.00        100\n",
      "    macro avg                                               85.14      85.39      85.25        100\n",
      "    weighted avg                                            86.00      86.00      85.99        100\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 54: val_loss reached 0.50618 (best 0.50618), saving model to \"/dli/task/nemo_experiments/TextClassification/2021-10-05_12-49-27/checkpoints/TextClassification--val_loss=0.51-epoch=4.ckpt\" as top 3\n",
      "Saving latest checkpoint...\n",
      "[NeMo W 2021-10-05 12:51:03 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/nemo/core/classes/modelPT.py:308: UserWarning: update_node() is deprecated, use OmegaConf.update(). (Since 2.0)\n",
      "      conf.update_node(conf_path, item.path)\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 25.3 s, total: 1min 33s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# start model training and save result\n",
    "# The training takes about 2 minutes to run\n",
    "trainer.fit(model)\n",
    "model.save_to(config.model.nemo_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model with `trainer.test`, which will automatically use the file path to the test set we updated in `config`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3df53967384a8ebe1a42dc6eef6f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-10-05 12:51:51 text_classification_model:165] test_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             75.00      75.00      75.00          4\n",
      "    label_id: 1                                            100.00     100.00     100.00          2\n",
      "    label_id: 2                                             75.00      75.00      75.00          4\n",
      "    -------------------\n",
      "    micro avg                                               80.00      80.00      80.00         10\n",
      "    macro avg                                               83.33      83.33      83.33         10\n",
      "    weighted avg                                            80.00      80.00      80.00         10\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.6855399012565613,\n",
       "  'test_precision': 79.99999237060547,\n",
       "  'test_f1': 79.99999237060547,\n",
       "  'test_recall': 79.99999237060547}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=model, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run inference using the inference samples from `config`. We can check on them by just printing directly from the `config.model.infer_samples` key object.  It displays as a list of strings.\n",
    "\n",
    "To run inference tor text classification, use the `model.classifytext` method.  The inferred labels are output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Germline mutations in BRCA1 are responsible for most cases of inherited breast and ovarian cancer ', 'The first predictive testing for Huntington disease  was based on analysis of linked polymorphic DNA markers to estimate the likelihood of inheriting the mutation for HD', 'Further studies suggested that low dilutions of C5D serum contain a factor or factors interfering at some step in the hemolytic assay of C5 rather than a true C5 inhibitor or inactivator']\n"
     ]
    }
   ],
   "source": [
    "print(config.model.infer_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifytext(queries=config.model.infer_samples, batch_size=64, max_seq_length=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.3 Exercise: Query the Model\n",
    "What if we wanted to specify additional queries for inference?  The `model.classifytext` method we just used specifies the queries, but they do not _have_ to be in the config file.  We can simply create a list of strings for our queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_queries = [\n",
    "    'Clustering of missense mutations in the ataxia-telangiectasia gene in a sporadic T-cell leukaemia',\n",
    "    'Myotonic dystrophy protein kinase is involved in the modulation of the Ca2+ homeostasis in skeletal muscle cells.',\n",
    "    'Constitutional RB1-gene mutations in patients with isolated unilateral retinoblastoma.',\n",
    "    'Hereditary deficiency of the fifth component of complement in man. I. Clinical, immunochemical, and family studies.'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference on the `my_queries` list.  If you get stuck, refer to the [solution](solutions/ex2.3.3.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Run inference over the my_queries list\n",
    "\n",
    "# Instantiate the OmegaConf object by loading the config file\n",
    "TC_DIR = \"/dli/task/nemo/examples/nlp/text_classification\"\n",
    "CONFIG_FILE = \"text_classification_config.yaml\"\n",
    "config = OmegaConf.load(TC_DIR + \"/conf/\" + CONFIG_FILE)\n",
    "\n",
    "# set the values we want to change\n",
    "NUM_CLASSES = 3\n",
    "MAX_SEQ_LENGTH = 128\n",
    "PATH_TO_TRAIN_FILE = \"/dli/task/data/NCBI_tc-3/train_nemo_format.tsv\"\n",
    "PATH_TO_VAL_FILE = \"/dli/task/data/NCBI_tc-3/dev_nemo_format.tsv\"\n",
    "PATH_TO_TEST_FILE = \"/dli/task/data/NCBI_tc-3/test_nemo_format.tsv\"\n",
    "# disease domain inference sample answers should be 0, 1, 2 \n",
    "my_queries = [\n",
    "    'Clustering of missense mutations in the ataxia-telangiectasia gene in a sporadic T-cell leukaemia',\n",
    "    'Myotonic dystrophy protein kinase is involved in the modulation of the Ca2+ homeostasis in skeletal muscle cells.',\n",
    "    'Constitutional RB1-gene mutations in patients with isolated unilateral retinoblastoma.',\n",
    "    'Hereditary deficiency of the fifth component of complement in man. I. Clinical, immunochemical, and family studies.'\n",
    "]\n",
    "MAX_EPOCHS = 5\n",
    "AMP_LEVEL = 'O1'\n",
    "PRECISION = 16\n",
    "LR = 5.0e-05\n",
    "\n",
    "# set the config values using omegaconf\n",
    "config.model.dataset.num_classes = NUM_CLASSES\n",
    "config.model.dataset.max_seq_length = MAX_SEQ_LENGTH\n",
    "config.model.train_ds.file_path = PATH_TO_TRAIN_FILE\n",
    "config.model.validation_ds.file_path = PATH_TO_VAL_FILE\n",
    "config.model.test_ds.file_path = PATH_TO_TEST_FILE\n",
    "config.model.infer_samples = my_queries\n",
    "config.trainer.max_epochs = MAX_EPOCHS\n",
    "config.trainer.amp_level = AMP_LEVEL\n",
    "config.trainer.precision = PRECISION\n",
    "config.model.optim.lr = LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 style=\"color:green;\">Congratulations!</h2>\n",
    "\n",
    "You've built a text classifier with three classes and learned:\n",
    "* How to use NeMo NLP model config files and scripts to quickly create experiments\n",
    "* How to override the config `model`, `trainer`, and `exp_manager settings`\n",
    "* How to train, evaluate, and infer a text classifier using a single command line\n",
    "* How to train, evaluate, and infer a text classifier using PyTorch Lightning\n",
    "\n",
    "You're ready to try a different NLP task.<br>\n",
    "\n",
    "Move on to [3.0 Build a Named Entity Recognizer](030_NamedEntityRecognition.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
