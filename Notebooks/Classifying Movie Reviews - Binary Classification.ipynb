{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0e6f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "466738a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify movie reviews as positive or negative based on the text content of the reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aaad3d",
   "metadata": {},
   "source": [
    "### IMDB Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edafa49",
   "metadata": {},
   "source": [
    "- Set of 50000 highly polarized reviews from the IMDB dataset.\n",
    "- Split into 25000 training set and 25000 test set.\n",
    "- Each set contains 50% positive reviews; 50% negative reviews.\n",
    "- Dataset comes preprocessed and packaged with Keras.\n",
    "- The reviews (sequences of word) have been turned into sequences of integers.\n",
    "- Each integer sttands for a specific word in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91f03519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the IMDB dataset.\n",
    "\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "284b5e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 34s 2us/step\n",
      "17473536/17464789 [==============================] - 34s 2us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "C:\\Users\\Jakkumun\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\datasets\\imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\Jakkumun\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\datasets\\imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "#num_words - means you keep the top 10000 most frequently occuring words in training data\n",
    "#rare words discarded.\n",
    "#manageable vector\n",
    "#train/test data - list of reviews\n",
    "#each review is a list of word indices\n",
    "#train/test labels - 0s and 1s (negative, positive review)\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b3804e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]\n",
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "216deccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no word index will exceed 10000\n",
    "\n",
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9067be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode one of the reviews back to English words\n",
    "# word_index() - dictionary mapping words to an index.\n",
    "\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "#reverses, mapping integer indices to words\n",
    "reverse_word_index = dict([(value,key) for (key,value) in word_index.items()])\n",
    "\n",
    "#decode review\n",
    "decoded_review = \"\".join([reverse_word_index.get(i - 3, \"?\") for i in train_data[0]])\n",
    "#indices are offset by 3 (0,1,2) - reserved indices for \"padding\", \"start of sequence\", \"unknown\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87457c28",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a25a4b",
   "metadata": {},
   "source": [
    "- Can't feed list of integers into a neural network; turn them to tensors.\n",
    "- Pad your lists so they all have same length.\n",
    "- Turn them into an integer tensor of shape(sample, word_indices)\n",
    "- Use as first layer in your network.(Embedding Layer) - integer tensors.\n",
    "\n",
    "- One-hot encode your lists to turn them into vectors of 0s and 1s.\n",
    "- Turning the sequence [3, 5] into a 10000 dimensional vector.\n",
    "- All 0s except for indices 3 and 5 will be 1s.\n",
    "- Use the first layer in your network a *Dense* Layer - handles floating pt data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a523c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding integer sequences into a binary matrix.\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fef6cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = int(10000)\n",
    "\n",
    "def vectorize_sequences (sequences, dimension=dimension):\n",
    "    #create an all-zero of matrix of shape(len(sequences), dimension) \n",
    "    result = np.zeros(len(sequences), dimension)\n",
    "    \n",
    "    for i, sequence in enumerate(sequences):\n",
    "        #set specific indices of results[i] to 1s\n",
    "        results[i, sequence] = 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06c82989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e2504f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "357e523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2503bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = mlb.fit_transform(train_data)\n",
    "x_test = mlb.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35f6fd4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "303752cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize labels\n",
    "\n",
    "y_train = np.asarray(train_labels).astype(\"float32\")\n",
    "y_test = np.asarray(test_labels).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3110d4",
   "metadata": {},
   "source": [
    "### Building The Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e6f3a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
