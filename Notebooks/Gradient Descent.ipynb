{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Building neural network by stacking *Dense* layers on top of each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras layer\n",
    "\n",
    "keras.layers.Dense(512, activation= \"relu\")\n",
    "\n",
    "#can be interpreted as a function\n",
    "#takes an input a 2D tensor and returns another 2D tensor\n",
    "#a new representation for the input tensor.\n",
    "#the function follows\n",
    "\n",
    "#where W is a 2D tensor and b is a vector, both attributes of a vector\n",
    "\n",
    "output = relu(dot(W, input) + b)\n",
    "\n",
    "#dot product (dot) between the input tensor and a tensor named W\n",
    "#an addition (+) between the resulting 2D tensor and a vector b;\n",
    "#relu operation. relu(x) is max(x, 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Element-wise Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#operations that are applied independently to each entry in the tensors being considered.\n",
    "#these operations are highly amenable to massively parallel implementations.\n",
    "#vectorized implementations\n",
    "#relu operations\n",
    "\n",
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2 #x is a 2D Numpy tensor\n",
    "    \n",
    "    x = x.copy()\n",
    "    for i in range (x.shape[0]):\n",
    "        for j in range (x.shape[1]):\n",
    "            x[i,j] = max(x[i,j], 0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#addition \n",
    "\n",
    "def naive_add(x,y): #two parameters\n",
    "    assert len(x.shape) == 2 #x and y are 2D NumPy tensors\n",
    "    assert x.shape == y.shape\n",
    "    \n",
    "    x = x.copy()\n",
    "    for i in range (x.shape[0]):\n",
    "        for j in range (x.shape[1]):\n",
    "            x[i,j] += y[i,j]\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in numpy you could\n",
    "\n",
    "z = x + y #element-wise addition\n",
    "z = np.maximum(z, 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Broadcasting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *naive_add* only supports addition of 2D tensors with identical shapes.\n",
    "- With the *Dense* layer we added a 2D tensor with a vector; the two tensors differ.\n",
    "- The smaller tensor will be broadcasted to match the shape of the larger tensor.\n",
    "    - *Broadcast axes* are added to the smaller tensor to match the ndim of the larger tensor.\n",
    "    - The smaller tensor is repeated alongside these new axes to match the full shape of the larger tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def naive_add(x,y): #two parameters\n",
    "    assert len(x.shape) == 2 \n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    \n",
    "    x = x.copy() #avoid overwriting input tensors\n",
    "    for i in range (x.shape[0]):\n",
    "        for j in range (x.shape[1]):\n",
    "            x[i,j] += y[i,j]\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3, 32, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applies to element-wise maximum operation\n",
    "#to two tensors of different shapes\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x = np.random.random((64, 3, 32, 10)) #random tensor with shape(64, 3, 32, 10)\n",
    "y = np.random.random((32,10)) #random tensor with shape(32,10)\n",
    "\n",
    "z = np.maximum(x, y)\n",
    "z.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor Dot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
